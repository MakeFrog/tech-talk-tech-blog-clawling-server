<!DOCTYPE html><html  lang="ko" data-capo=""><head><meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>이미지와 음성을 아우르는 카카오의 멀티모달 언어모델 Kanana-o 알아보기 - tech.kakao.com</title>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-MS10Z6SM95"></script>
<script src="https://t1.kakaocdn.net/kakao_js_sdk/2.6.0/kakao.min.js" integrity="sha384-6MFdIr0zOira1CHQkedUqJVql0YtcZA1P0nbPrQYJXVJZUkTk/oX4U9GhUIs3/z8" crossorigin="anonymous"></script>
<style>@charset "UTF-8";@font-face{font-family:KakaoBig;font-weight:400;src:local("☺"),url(/_nuxt/KakaoBig-Regular-v1.0.B1i0cA4z.woff2) format("woff2"),url(/_nuxt/KakaoBig-Regular-v1.0.B2Yafqhx.woff) format("woff")}@font-face{font-family:KakaoBig;font-weight:700;src:local("☺"),url(/_nuxt/KakaoBig-Bold-v1.0.D-TiHNti.woff2) format("woff2"),url(/_nuxt/KakaoBig-Bold-v1.0.CZ3t6CPH.woff) format("woff")}@font-face{font-family:KakaoBig;font-weight:800;src:local("☺"),url(/_nuxt/KakaoBig_ExtraBold_OTF.BbO7PRd0.woff2) format("woff2"),url(/_nuxt/KakaoBig_ExtraBold_OTF.lhLfzQOZ.woff) format("woff")}html{font-size:14px}blockquote,body,button,code,dd,div,dl,dt,fieldset,form,h1,h2,h3,h4,h5,h6,input,legend,li,ol,p,pre,select,td,textarea,th,ul{margin:0;padding:0}fieldset,img{border:0}dl,li,menu,ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}button,input,select,textarea{font-size:100%;vertical-align:middle}button{background-color:transparent;border:0;cursor:pointer}table{border-collapse:collapse;border-spacing:0}body{-webkit-text-size-adjust:none}input:checked[type=checkbox]{-webkit-appearance:checkbox;background-color:#666}html input[type=button],input[type=email],input[type=password],input[type=reset],input[type=search],input[type=submit],input[type=tel],input[type=text]{-webkit-appearance:none;border-radius:0}input[type=search]::-webkit-search-cancel-button{-webkit-appearance:none}body{background:#fff}body,button,input,select,td,textarea,th{color:#000;font-family:KakaoBig,Apple SD Gothic Neo,Malgun Gothic,맑은 고딕,sans-serif;font-size:1rem;line-height:1.5}a{color:#333}a,a:active,a:hover{text-decoration:none}address,caption,cite,code,dfn,em,var{font-style:normal;font-weight:400}.direct-link{height:1px;left:0;position:absolute;top:-1px;z-index:1000}.direct-link a{background:#333;color:#fff;font-weight:700;padding:5px 10px;position:absolute;text-decoration:none;top:-999px;white-space:nowrap}.direct-link a:focus{top:0}.ir_pm{color:transparent;font-size:1px;line-height:0}.ir_pm,.ir_wa{display:block;overflow:hidden}.ir_wa{height:100%;position:relative;width:100%;z-index:-1}.ir_caption{font-size:1px;width:1px}.ir_caption,.screen_out{line-height:0;overflow:hidden;text-indent:-9999px}.screen_out{height:0;position:absolute;width:0}.show{display:block}.hide{display:none}body.layer_open{overflow:hidden}</style>
<style>:root{--logo-txt:#000;--strong-title:#4f46e5;--sub-title:#60a5fa;--meta-data:#9ca3af;--category-gray:#4b5563;--subTxt-gray:#475569;--descTxt-gray:#64748b;--bg-footer:#f1f5f9;--title-bk:#1e293b;--desc-bk:#334155;--detail-desc:#374151;--detail-title:#111827;--paging-gray:#f3f4f6;--list-number:#6b7280;--list-bullet:#d1d5db}</style>
<style>.preview{margin:0 auto;max-width:768px;overflow-wrap:break-word}.preview em{font-style:italic}.preview p{color:var(--detail-desc);font-size:1.14rem;line-height:1.75;margin:1.5rem 0 1rem}.preview h2,.preview h3,.preview h4,.preview h5,.preview h6{margin:2rem 0 1rem}.preview h2,.preview h3{color:var(--detail-title);font-weight:700;line-height:32px}.preview h2{font-size:24px}.preview h3{font-size:20px}.preview h4{color:var(--detail-title);font-size:16px;font-weight:700;line-height:24px}.preview h5,.preview h6{color:var(--detail-desc);font-size:16px;font-weight:400;line-height:24px}.preview blockquote{border-left:4px solid #e5e7eb;color:var(--detail-title);font-size:1.14rem;font-style:italic;font-weight:400;line-height:1.75;margin:1rem 0;padding-left:16px}.preview blockquote :first-child{margin-top:0}.preview blockquote :last-child{margin-bottom:0}.preview ol,.preview ul{color:var(--detail-desc);font-size:1.14rem;line-height:1.75;margin:1rem 0;padding-left:32px}.preview ol li,.preview ul li{margin:.5rem 0}.preview ol li :first-child,.preview ul li :first-child{margin-top:0}.preview ol li :last-child,.preview ul li :last-child{margin-bottom:0}.preview ol>li{list-style-type:decimal}.preview ol>li::marker{color:var(--list-number)}.preview ul>li{list-style-type:disc}.preview ul>li::marker{color:var(--list-bullet)}.preview hr{border-color:#e5e7eb;margin:1rem 0}.preview table{color:var(--detail-desc);line-height:24px;width:100%}.preview table th{border-bottom:1px solid #d1d5db;color:var(--detail-title);font-weight:700;padding:4px 8px 12px}.preview table td{border-bottom:1px solid #e5e7eb;min-width:60px;padding:8px;word-break:break-all}.preview pre,.preview pre[class*=language-]{background:#161b22;border-radius:6px;box-sizing:border-box;color:#c9d1d9;font-size:1em;-webkit-hyphens:none;hyphens:none;margin:1.5rem 0;overflow:auto;padding:1em;-moz-tab-size:4;-o-tab-size:4;tab-size:4;white-space:pre}.preview pre code,.preview pre[class*=language-] code{background:transparent;border:none;color:unset;font-weight:unset;padding:0}.preview code[class*=language-],.preview pre[class*=language-]{font-size:1em}.preview code{background:#ddd;border:1px solid #bcbec0;border-radius:20px;font:85% Monaco,Consolas,Andale Mono,DejaVu Sans Mono,monospace;padding:.2em .4em;white-space:break-spaces}.preview u{font-weight:400}.preview img,.preview video{height:auto}.preview iframe,.preview img,.preview video{display:block;margin:0 auto;max-width:100%}.preview p:has(iframe){height:0;overflow:hidden;padding-top:56.24%;position:relative}.preview p:has(iframe) iframe{border:0;height:100%;left:0;position:absolute;top:0;width:100%}.preview a{font-weight:700;text-decoration:underline;word-break:break-all}.preview figcaption{color:#000;font-size:1rem;text-align:center}.preview figcaption:before{content:"< "}.preview figcaption:after{content:" >"}.preview .table-wrapper{margin:1.5rem 0;overflow-x:auto;width:100%}.preview canvas,.preview dl,.preview form{margin:1rem 0}.preview dd{margin:.5rem 0;margin-inline-start:40px}.preview dt{font-weight:700}.preview dt:after{content:": "}</style>
<style>@font-face{font-family:KaTeX_AMS;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_AMS-Regular.BQhdFMY1.woff2) format("woff2"),url(/_nuxt/KaTeX_AMS-Regular.DMm9YOAa.woff) format("woff"),url(/_nuxt/KaTeX_AMS-Regular.DRggAlZN.ttf) format("truetype")}@font-face{font-family:KaTeX_Caligraphic;font-style:normal;font-weight:700;src:url(/_nuxt/KaTeX_Caligraphic-Bold.Dq_IR9rO.woff2) format("woff2"),url(/_nuxt/KaTeX_Caligraphic-Bold.BEiXGLvX.woff) format("woff"),url(/_nuxt/KaTeX_Caligraphic-Bold.ATXxdsX0.ttf) format("truetype")}@font-face{font-family:KaTeX_Caligraphic;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Caligraphic-Regular.Di6jR-x-.woff2) format("woff2"),url(/_nuxt/KaTeX_Caligraphic-Regular.CTRA-rTL.woff) format("woff"),url(/_nuxt/KaTeX_Caligraphic-Regular.wX97UBjC.ttf) format("truetype")}@font-face{font-family:KaTeX_Fraktur;font-style:normal;font-weight:700;src:url(/_nuxt/KaTeX_Fraktur-Bold.CL6g_b3V.woff2) format("woff2"),url(/_nuxt/KaTeX_Fraktur-Bold.BsDP51OF.woff) format("woff"),url(/_nuxt/KaTeX_Fraktur-Bold.BdnERNNW.ttf) format("truetype")}@font-face{font-family:KaTeX_Fraktur;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Fraktur-Regular.CTYiF6lA.woff2) format("woff2"),url(/_nuxt/KaTeX_Fraktur-Regular.Dxdc4cR9.woff) format("woff"),url(/_nuxt/KaTeX_Fraktur-Regular.CB_wures.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:700;src:url(/_nuxt/KaTeX_Main-Bold.Cx986IdX.woff2) format("woff2"),url(/_nuxt/KaTeX_Main-Bold.Jm3AIy58.woff) format("woff"),url(/_nuxt/KaTeX_Main-Bold.waoOVXN0.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:700;src:url(/_nuxt/KaTeX_Main-BoldItalic.DxDJ3AOS.woff2) format("woff2"),url(/_nuxt/KaTeX_Main-BoldItalic.SpSLRI95.woff) format("woff"),url(/_nuxt/KaTeX_Main-BoldItalic.DzxPMmG6.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:400;src:url(/_nuxt/KaTeX_Main-Italic.NWA7e6Wa.woff2) format("woff2"),url(/_nuxt/KaTeX_Main-Italic.BMLOBm91.woff) format("woff"),url(/_nuxt/KaTeX_Main-Italic.3WenGoN9.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Main-Regular.B22Nviop.woff2) format("woff2"),url(/_nuxt/KaTeX_Main-Regular.Dr94JaBh.woff) format("woff"),url(/_nuxt/KaTeX_Main-Regular.ypZvNtVU.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:700;src:url(/_nuxt/KaTeX_Math-BoldItalic.CZnvNsCZ.woff2) format("woff2"),url(/_nuxt/KaTeX_Math-BoldItalic.iY-2wyZ7.woff) format("woff"),url(/_nuxt/KaTeX_Math-BoldItalic.B3XSjfu4.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:400;src:url(/_nuxt/KaTeX_Math-Italic.t53AETM-.woff2) format("woff2"),url(/_nuxt/KaTeX_Math-Italic.DA0__PXp.woff) format("woff"),url(/_nuxt/KaTeX_Math-Italic.flOr_0UB.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:normal;font-weight:700;src:url(/_nuxt/KaTeX_SansSerif-Bold.D1sUS0GD.woff2) format("woff2"),url(/_nuxt/KaTeX_SansSerif-Bold.DbIhKOiC.woff) format("woff"),url(/_nuxt/KaTeX_SansSerif-Bold.CFMepnvq.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:italic;font-weight:400;src:url(/_nuxt/KaTeX_SansSerif-Italic.C3H0VqGB.woff2) format("woff2"),url(/_nuxt/KaTeX_SansSerif-Italic.DN2j7dab.woff) format("woff"),url(/_nuxt/KaTeX_SansSerif-Italic.YYjJ1zSn.ttf) format("truetype")}@font-face{font-family:"KaTeX_SansSerif";font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_SansSerif-Regular.DDBCnlJ7.woff2) format("woff2"),url(/_nuxt/KaTeX_SansSerif-Regular.CS6fqUqJ.woff) format("woff"),url(/_nuxt/KaTeX_SansSerif-Regular.BNo7hRIc.ttf) format("truetype")}@font-face{font-family:KaTeX_Script;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Script-Regular.D3wIWfF6.woff2) format("woff2"),url(/_nuxt/KaTeX_Script-Regular.D5yQViql.woff) format("woff"),url(/_nuxt/KaTeX_Script-Regular.C5JkGWo-.ttf) format("truetype")}@font-face{font-family:KaTeX_Size1;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Size1-Regular.mCD8mA8B.woff2) format("woff2"),url(/_nuxt/KaTeX_Size1-Regular.C195tn64.woff) format("woff"),url(/_nuxt/KaTeX_Size1-Regular.Dbsnue_I.ttf) format("truetype")}@font-face{font-family:KaTeX_Size2;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Size2-Regular.Dy4dx90m.woff2) format("woff2"),url(/_nuxt/KaTeX_Size2-Regular.oD1tc_U0.woff) format("woff"),url(/_nuxt/KaTeX_Size2-Regular.B7gKUWhC.ttf) format("truetype")}@font-face{font-family:KaTeX_Size3;font-style:normal;font-weight:400;src:url(data:font/woff2;base64,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) format("woff2"),url(/_nuxt/KaTeX_Size3-Regular.CTq5MqoE.woff) format("woff"),url(/_nuxt/KaTeX_Size3-Regular.DgpXs0kz.ttf) format("truetype")}@font-face{font-family:KaTeX_Size4;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Size4-Regular.Dl5lxZxV.woff2) format("woff2"),url(/_nuxt/KaTeX_Size4-Regular.BF-4gkZK.woff) format("woff"),url(/_nuxt/KaTeX_Size4-Regular.DWFBv043.ttf) format("truetype")}@font-face{font-family:KaTeX_Typewriter;font-style:normal;font-weight:400;src:url(/_nuxt/KaTeX_Typewriter-Regular.CO6r4hn1.woff2) format("woff2"),url(/_nuxt/KaTeX_Typewriter-Regular.C0xS9mPB.woff) format("woff"),url(/_nuxt/KaTeX_Typewriter-Regular.D3Ib7_Hf.ttf) format("truetype")}.katex{font:normal 1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;text-indent:0;text-rendering:auto}.katex *{-ms-high-contrast-adjust:none!important;border-color:currentColor}.katex .katex-version:after{content:"0.16.11"}.katex .katex-mathml{position:absolute;clip:rect(1px,1px,1px,1px);border:0;height:1px;overflow:hidden;padding:0;width:1px}.katex .katex-html>.newline{display:block}.katex .base{position:relative;white-space:nowrap;width:-moz-min-content;width:min-content}.katex .base,.katex .strut{display:inline-block}.katex .textbf{font-weight:700}.katex .textit{font-style:italic}.katex .textrm{font-family:KaTeX_Main}.katex .textsf{font-family:KaTeX_SansSerif}.katex .texttt{font-family:KaTeX_Typewriter}.katex .mathnormal{font-family:KaTeX_Math;font-style:italic}.katex .mathit{font-family:KaTeX_Main;font-style:italic}.katex .mathrm{font-style:normal}.katex .mathbf{font-family:KaTeX_Main;font-weight:700}.katex .boldsymbol{font-family:KaTeX_Math;font-style:italic;font-weight:700}.katex .amsrm,.katex .mathbb,.katex .textbb{font-family:KaTeX_AMS}.katex .mathcal{font-family:KaTeX_Caligraphic}.katex .mathfrak,.katex .textfrak{font-family:KaTeX_Fraktur}.katex .mathboldfrak,.katex .textboldfrak{font-family:KaTeX_Fraktur;font-weight:700}.katex .mathtt{font-family:KaTeX_Typewriter}.katex .mathscr,.katex .textscr{font-family:KaTeX_Script}.katex .mathsf,.katex .textsf{font-family:KaTeX_SansSerif}.katex .mathboldsf,.katex .textboldsf{font-family:KaTeX_SansSerif;font-weight:700}.katex .mathitsf,.katex .textitsf{font-family:KaTeX_SansSerif;font-style:italic}.katex .mainrm{font-family:KaTeX_Main;font-style:normal}.katex .vlist-t{border-collapse:collapse;display:inline-table;table-layout:fixed}.katex .vlist-r{display:table-row}.katex .vlist{display:table-cell;position:relative;vertical-align:bottom}.katex .vlist>span{display:block;height:0;position:relative}.katex .vlist>span>span{display:inline-block}.katex .vlist>span>.pstrut{overflow:hidden;width:0}.katex .vlist-t2{margin-right:-2px}.katex .vlist-s{display:table-cell;font-size:1px;min-width:2px;vertical-align:bottom;width:2px}.katex .vbox{align-items:baseline;display:inline-flex;flex-direction:column}.katex .hbox{width:100%}.katex .hbox,.katex .thinbox{display:inline-flex;flex-direction:row}.katex .thinbox{max-width:0;width:0}.katex .msupsub{text-align:left}.katex .mfrac>span>span{text-align:center}.katex .mfrac .frac-line{border-bottom-style:solid;display:inline-block;width:100%}.katex .hdashline,.katex .hline,.katex .mfrac .frac-line,.katex .overline .overline-line,.katex .rule,.katex .underline .underline-line{min-height:1px}.katex .mspace{display:inline-block}.katex .clap,.katex .llap,.katex .rlap{position:relative;width:0}.katex .clap>.inner,.katex .llap>.inner,.katex .rlap>.inner{position:absolute}.katex .clap>.fix,.katex .llap>.fix,.katex .rlap>.fix{display:inline-block}.katex .llap>.inner{right:0}.katex .clap>.inner,.katex .rlap>.inner{left:0}.katex .clap>.inner>span{margin-left:-50%;margin-right:50%}.katex .rule{border:0 solid;display:inline-block;position:relative}.katex .hline,.katex .overline .overline-line,.katex .underline .underline-line{border-bottom-style:solid;display:inline-block;width:100%}.katex .hdashline{border-bottom-style:dashed;display:inline-block;width:100%}.katex .sqrt>.root{margin-left:.2777777778em;margin-right:-.5555555556em}.katex .fontsize-ensurer.reset-size1.size1,.katex .sizing.reset-size1.size1{font-size:1em}.katex .fontsize-ensurer.reset-size1.size2,.katex .sizing.reset-size1.size2{font-size:1.2em}.katex .fontsize-ensurer.reset-size1.size3,.katex .sizing.reset-size1.size3{font-size:1.4em}.katex .fontsize-ensurer.reset-size1.size4,.katex .sizing.reset-size1.size4{font-size:1.6em}.katex .fontsize-ensurer.reset-size1.size5,.katex .sizing.reset-size1.size5{font-size:1.8em}.katex .fontsize-ensurer.reset-size1.size6,.katex .sizing.reset-size1.size6{font-size:2em}.katex .fontsize-ensurer.reset-size1.size7,.katex .sizing.reset-size1.size7{font-size:2.4em}.katex .fontsize-ensurer.reset-size1.size8,.katex .sizing.reset-size1.size8{font-size:2.88em}.katex .fontsize-ensurer.reset-size1.size9,.katex .sizing.reset-size1.size9{font-size:3.456em}.katex .fontsize-ensurer.reset-size1.size10,.katex .sizing.reset-size1.size10{font-size:4.148em}.katex .fontsize-ensurer.reset-size1.size11,.katex .sizing.reset-size1.size11{font-size:4.976em}.katex .fontsize-ensurer.reset-size2.size1,.katex .sizing.reset-size2.size1{font-size:.8333333333em}.katex .fontsize-ensurer.reset-size2.size2,.katex .sizing.reset-size2.size2{font-size:1em}.katex .fontsize-ensurer.reset-size2.size3,.katex .sizing.reset-size2.size3{font-size:1.1666666667em}.katex .fontsize-ensurer.reset-size2.size4,.katex .sizing.reset-size2.size4{font-size:1.3333333333em}.katex .fontsize-ensurer.reset-size2.size5,.katex .sizing.reset-size2.size5{font-size:1.5em}.katex .fontsize-ensurer.reset-size2.size6,.katex .sizing.reset-size2.size6{font-size:1.6666666667em}.katex .fontsize-ensurer.reset-size2.size7,.katex .sizing.reset-size2.size7{font-size:2em}.katex .fontsize-ensurer.reset-size2.size8,.katex .sizing.reset-size2.size8{font-size:2.4em}.katex .fontsize-ensurer.reset-size2.size9,.katex .sizing.reset-size2.size9{font-size:2.88em}.katex .fontsize-ensurer.reset-size2.size10,.katex .sizing.reset-size2.size10{font-size:3.4566666667em}.katex .fontsize-ensurer.reset-size2.size11,.katex .sizing.reset-size2.size11{font-size:4.1466666667em}.katex .fontsize-ensurer.reset-size3.size1,.katex .sizing.reset-size3.size1{font-size:.7142857143em}.katex .fontsize-ensurer.reset-size3.size2,.katex .sizing.reset-size3.size2{font-size:.8571428571em}.katex .fontsize-ensurer.reset-size3.size3,.katex .sizing.reset-size3.size3{font-size:1em}.katex .fontsize-ensurer.reset-size3.size4,.katex .sizing.reset-size3.size4{font-size:1.1428571429em}.katex .fontsize-ensurer.reset-size3.size5,.katex .sizing.reset-size3.size5{font-size:1.2857142857em}.katex .fontsize-ensurer.reset-size3.size6,.katex .sizing.reset-size3.size6{font-size:1.4285714286em}.katex .fontsize-ensurer.reset-size3.size7,.katex .sizing.reset-size3.size7{font-size:1.7142857143em}.katex .fontsize-ensurer.reset-size3.size8,.katex .sizing.reset-size3.size8{font-size:2.0571428571em}.katex .fontsize-ensurer.reset-size3.size9,.katex .sizing.reset-size3.size9{font-size:2.4685714286em}.katex .fontsize-ensurer.reset-size3.size10,.katex .sizing.reset-size3.size10{font-size:2.9628571429em}.katex .fontsize-ensurer.reset-size3.size11,.katex .sizing.reset-size3.size11{font-size:3.5542857143em}.katex .fontsize-ensurer.reset-size4.size1,.katex .sizing.reset-size4.size1{font-size:.625em}.katex .fontsize-ensurer.reset-size4.size2,.katex .sizing.reset-size4.size2{font-size:.75em}.katex .fontsize-ensurer.reset-size4.size3,.katex .sizing.reset-size4.size3{font-size:.875em}.katex .fontsize-ensurer.reset-size4.size4,.katex .sizing.reset-size4.size4{font-size:1em}.katex .fontsize-ensurer.reset-size4.size5,.katex .sizing.reset-size4.size5{font-size:1.125em}.katex .fontsize-ensurer.reset-size4.size6,.katex .sizing.reset-size4.size6{font-size:1.25em}.katex .fontsize-ensurer.reset-size4.size7,.katex .sizing.reset-size4.size7{font-size:1.5em}.katex .fontsize-ensurer.reset-size4.size8,.katex .sizing.reset-size4.size8{font-size:1.8em}.katex .fontsize-ensurer.reset-size4.size9,.katex .sizing.reset-size4.size9{font-size:2.16em}.katex .fontsize-ensurer.reset-size4.size10,.katex .sizing.reset-size4.size10{font-size:2.5925em}.katex .fontsize-ensurer.reset-size4.size11,.katex .sizing.reset-size4.size11{font-size:3.11em}.katex .fontsize-ensurer.reset-size5.size1,.katex .sizing.reset-size5.size1{font-size:.5555555556em}.katex .fontsize-ensurer.reset-size5.size2,.katex .sizing.reset-size5.size2{font-size:.6666666667em}.katex .fontsize-ensurer.reset-size5.size3,.katex .sizing.reset-size5.size3{font-size:.7777777778em}.katex .fontsize-ensurer.reset-size5.size4,.katex .sizing.reset-size5.size4{font-size:.8888888889em}.katex .fontsize-ensurer.reset-size5.size5,.katex .sizing.reset-size5.size5{font-size:1em}.katex .fontsize-ensurer.reset-size5.size6,.katex .sizing.reset-size5.size6{font-size:1.1111111111em}.katex .fontsize-ensurer.reset-size5.size7,.katex .sizing.reset-size5.size7{font-size:1.3333333333em}.katex .fontsize-ensurer.reset-size5.size8,.katex .sizing.reset-size5.size8{font-size:1.6em}.katex .fontsize-ensurer.reset-size5.size9,.katex .sizing.reset-size5.size9{font-size:1.92em}.katex .fontsize-ensurer.reset-size5.size10,.katex .sizing.reset-size5.size10{font-size:2.3044444444em}.katex .fontsize-ensurer.reset-size5.size11,.katex .sizing.reset-size5.size11{font-size:2.7644444444em}.katex .fontsize-ensurer.reset-size6.size1,.katex .sizing.reset-size6.size1{font-size:.5em}.katex .fontsize-ensurer.reset-size6.size2,.katex .sizing.reset-size6.size2{font-size:.6em}.katex .fontsize-ensurer.reset-size6.size3,.katex .sizing.reset-size6.size3{font-size:.7em}.katex .fontsize-ensurer.reset-size6.size4,.katex .sizing.reset-size6.size4{font-size:.8em}.katex .fontsize-ensurer.reset-size6.size5,.katex .sizing.reset-size6.size5{font-size:.9em}.katex .fontsize-ensurer.reset-size6.size6,.katex .sizing.reset-size6.size6{font-size:1em}.katex .fontsize-ensurer.reset-size6.size7,.katex .sizing.reset-size6.size7{font-size:1.2em}.katex .fontsize-ensurer.reset-size6.size8,.katex .sizing.reset-size6.size8{font-size:1.44em}.katex .fontsize-ensurer.reset-size6.size9,.katex .sizing.reset-size6.size9{font-size:1.728em}.katex .fontsize-ensurer.reset-size6.size10,.katex .sizing.reset-size6.size10{font-size:2.074em}.katex .fontsize-ensurer.reset-size6.size11,.katex .sizing.reset-size6.size11{font-size:2.488em}.katex .fontsize-ensurer.reset-size7.size1,.katex .sizing.reset-size7.size1{font-size:.4166666667em}.katex .fontsize-ensurer.reset-size7.size2,.katex .sizing.reset-size7.size2{font-size:.5em}.katex .fontsize-ensurer.reset-size7.size3,.katex .sizing.reset-size7.size3{font-size:.5833333333em}.katex .fontsize-ensurer.reset-size7.size4,.katex .sizing.reset-size7.size4{font-size:.6666666667em}.katex .fontsize-ensurer.reset-size7.size5,.katex .sizing.reset-size7.size5{font-size:.75em}.katex .fontsize-ensurer.reset-size7.size6,.katex .sizing.reset-size7.size6{font-size:.8333333333em}.katex .fontsize-ensurer.reset-size7.size7,.katex .sizing.reset-size7.size7{font-size:1em}.katex .fontsize-ensurer.reset-size7.size8,.katex .sizing.reset-size7.size8{font-size:1.2em}.katex .fontsize-ensurer.reset-size7.size9,.katex .sizing.reset-size7.size9{font-size:1.44em}.katex .fontsize-ensurer.reset-size7.size10,.katex .sizing.reset-size7.size10{font-size:1.7283333333em}.katex .fontsize-ensurer.reset-size7.size11,.katex .sizing.reset-size7.size11{font-size:2.0733333333em}.katex .fontsize-ensurer.reset-size8.size1,.katex .sizing.reset-size8.size1{font-size:.3472222222em}.katex .fontsize-ensurer.reset-size8.size2,.katex .sizing.reset-size8.size2{font-size:.4166666667em}.katex .fontsize-ensurer.reset-size8.size3,.katex .sizing.reset-size8.size3{font-size:.4861111111em}.katex .fontsize-ensurer.reset-size8.size4,.katex .sizing.reset-size8.size4{font-size:.5555555556em}.katex .fontsize-ensurer.reset-size8.size5,.katex .sizing.reset-size8.size5{font-size:.625em}.katex .fontsize-ensurer.reset-size8.size6,.katex .sizing.reset-size8.size6{font-size:.6944444444em}.katex .fontsize-ensurer.reset-size8.size7,.katex .sizing.reset-size8.size7{font-size:.8333333333em}.katex .fontsize-ensurer.reset-size8.size8,.katex .sizing.reset-size8.size8{font-size:1em}.katex .fontsize-ensurer.reset-size8.size9,.katex .sizing.reset-size8.size9{font-size:1.2em}.katex .fontsize-ensurer.reset-size8.size10,.katex .sizing.reset-size8.size10{font-size:1.4402777778em}.katex .fontsize-ensurer.reset-size8.size11,.katex .sizing.reset-size8.size11{font-size:1.7277777778em}.katex .fontsize-ensurer.reset-size9.size1,.katex .sizing.reset-size9.size1{font-size:.2893518519em}.katex .fontsize-ensurer.reset-size9.size2,.katex .sizing.reset-size9.size2{font-size:.3472222222em}.katex .fontsize-ensurer.reset-size9.size3,.katex .sizing.reset-size9.size3{font-size:.4050925926em}.katex .fontsize-ensurer.reset-size9.size4,.katex .sizing.reset-size9.size4{font-size:.462962963em}.katex .fontsize-ensurer.reset-size9.size5,.katex .sizing.reset-size9.size5{font-size:.5208333333em}.katex .fontsize-ensurer.reset-size9.size6,.katex .sizing.reset-size9.size6{font-size:.5787037037em}.katex .fontsize-ensurer.reset-size9.size7,.katex .sizing.reset-size9.size7{font-size:.6944444444em}.katex .fontsize-ensurer.reset-size9.size8,.katex .sizing.reset-size9.size8{font-size:.8333333333em}.katex .fontsize-ensurer.reset-size9.size9,.katex .sizing.reset-size9.size9{font-size:1em}.katex .fontsize-ensurer.reset-size9.size10,.katex .sizing.reset-size9.size10{font-size:1.2002314815em}.katex .fontsize-ensurer.reset-size9.size11,.katex .sizing.reset-size9.size11{font-size:1.4398148148em}.katex .fontsize-ensurer.reset-size10.size1,.katex .sizing.reset-size10.size1{font-size:.2410800386em}.katex .fontsize-ensurer.reset-size10.size2,.katex .sizing.reset-size10.size2{font-size:.2892960463em}.katex .fontsize-ensurer.reset-size10.size3,.katex .sizing.reset-size10.size3{font-size:.337512054em}.katex .fontsize-ensurer.reset-size10.size4,.katex .sizing.reset-size10.size4{font-size:.3857280617em}.katex .fontsize-ensurer.reset-size10.size5,.katex .sizing.reset-size10.size5{font-size:.4339440694em}.katex .fontsize-ensurer.reset-size10.size6,.katex .sizing.reset-size10.size6{font-size:.4821600771em}.katex .fontsize-ensurer.reset-size10.size7,.katex .sizing.reset-size10.size7{font-size:.5785920926em}.katex .fontsize-ensurer.reset-size10.size8,.katex .sizing.reset-size10.size8{font-size:.6943105111em}.katex .fontsize-ensurer.reset-size10.size9,.katex .sizing.reset-size10.size9{font-size:.8331726133em}.katex .fontsize-ensurer.reset-size10.size10,.katex .sizing.reset-size10.size10{font-size:1em}.katex .fontsize-ensurer.reset-size10.size11,.katex .sizing.reset-size10.size11{font-size:1.1996142719em}.katex .fontsize-ensurer.reset-size11.size1,.katex .sizing.reset-size11.size1{font-size:.2009646302em}.katex .fontsize-ensurer.reset-size11.size2,.katex .sizing.reset-size11.size2{font-size:.2411575563em}.katex .fontsize-ensurer.reset-size11.size3,.katex .sizing.reset-size11.size3{font-size:.2813504823em}.katex .fontsize-ensurer.reset-size11.size4,.katex .sizing.reset-size11.size4{font-size:.3215434084em}.katex .fontsize-ensurer.reset-size11.size5,.katex .sizing.reset-size11.size5{font-size:.3617363344em}.katex .fontsize-ensurer.reset-size11.size6,.katex .sizing.reset-size11.size6{font-size:.4019292605em}.katex .fontsize-ensurer.reset-size11.size7,.katex .sizing.reset-size11.size7{font-size:.4823151125em}.katex .fontsize-ensurer.reset-size11.size8,.katex .sizing.reset-size11.size8{font-size:.578778135em}.katex .fontsize-ensurer.reset-size11.size9,.katex .sizing.reset-size11.size9{font-size:.6945337621em}.katex .fontsize-ensurer.reset-size11.size10,.katex .sizing.reset-size11.size10{font-size:.8336012862em}.katex .fontsize-ensurer.reset-size11.size11,.katex .sizing.reset-size11.size11{font-size:1em}.katex .delimsizing.size1{font-family:KaTeX_Size1}.katex .delimsizing.size2{font-family:KaTeX_Size2}.katex .delimsizing.size3{font-family:KaTeX_Size3}.katex .delimsizing.size4{font-family:KaTeX_Size4}.katex .delimsizing.mult .delim-size1>span{font-family:KaTeX_Size1}.katex .delimsizing.mult .delim-size4>span{font-family:KaTeX_Size4}.katex .nulldelimiter{display:inline-block;width:.12em}.katex .delimcenter,.katex .op-symbol{position:relative}.katex .op-symbol.small-op{font-family:KaTeX_Size1}.katex .op-symbol.large-op{font-family:KaTeX_Size2}.katex .accent>.vlist-t,.katex .op-limits>.vlist-t{text-align:center}.katex .accent .accent-body{position:relative}.katex .accent .accent-body:not(.accent-full){width:0}.katex .overlay{display:block}.katex .mtable .vertical-separator{display:inline-block;min-width:1px}.katex .mtable .arraycolsep{display:inline-block}.katex .mtable .col-align-c>.vlist-t{text-align:center}.katex .mtable .col-align-l>.vlist-t{text-align:left}.katex .mtable .col-align-r>.vlist-t{text-align:right}.katex .svg-align{text-align:left}.katex svg{display:block;height:inherit;position:absolute;width:100%;fill:currentColor;stroke:currentColor;fill-rule:nonzero;fill-opacity:1;stroke-width:1;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1}.katex svg path{stroke:none}.katex img{border-style:none;max-height:none;max-width:none;min-height:0;min-width:0}.katex .stretchy{display:block;overflow:hidden;position:relative;width:100%}.katex .stretchy:after,.katex .stretchy:before{content:""}.katex .hide-tail{overflow:hidden;position:relative;width:100%}.katex .halfarrow-left{left:0;overflow:hidden;position:absolute;width:50.2%}.katex .halfarrow-right{overflow:hidden;position:absolute;right:0;width:50.2%}.katex .brace-left{left:0;overflow:hidden;position:absolute;width:25.1%}.katex .brace-center{left:25%;overflow:hidden;position:absolute;width:50%}.katex .brace-right{overflow:hidden;position:absolute;right:0;width:25.1%}.katex .x-arrow-pad{padding:0 .5em}.katex .cd-arrow-pad{padding:0 .55556em 0 .27778em}.katex .mover,.katex .munder,.katex .x-arrow{text-align:center}.katex .boxpad{padding:0 .3em}.katex .fbox,.katex .fcolorbox{border:.04em solid;box-sizing:border-box}.katex .cancel-pad{padding:0 .2em}.katex .cancel-lap{margin-left:-.2em;margin-right:-.2em}.katex .sout{border-bottom-style:solid;border-bottom-width:.08em}.katex .angl{border-right:.049em solid;border-top:.049em solid;box-sizing:border-box;margin-right:.03889em}.katex .anglpad{padding:0 .03889em}.katex .eqn-num:before{content:"(" counter(katexEqnNo) ")";counter-increment:katexEqnNo}.katex .mml-eqn-num:before{content:"(" counter(mmlEqnNo) ")";counter-increment:mmlEqnNo}.katex .mtr-glue{width:50%}.katex .cd-vert-arrow{display:inline-block;position:relative}.katex .cd-label-left{display:inline-block;position:absolute;right:calc(50% + .3em);text-align:left}.katex .cd-label-right{display:inline-block;left:calc(50% + .3em);position:absolute;text-align:right}.katex-display{display:block;margin:1em 0;text-align:center}.katex-display>.katex{display:block;text-align:center;white-space:nowrap}.katex-display>.katex>.katex-html{display:block;position:relative}.katex-display>.katex>.katex-html>.tag{position:absolute;right:0}.katex-display.leqno>.katex>.katex-html>.tag{left:0;right:auto}.katex-display.fleqn>.katex{padding-left:2em;text-align:left}body{counter-reset:katexEqnNo mmlEqnNo}</style>
<style>code[class*=language-],pre[class*=language-]{color:#c9d1d9;direction:ltr;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:13px;-webkit-hyphens:none;hyphens:none;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;text-align:left;text-shadow:none;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-]::-moz-selection,pre[class*=language-]::-moz-selection{background:#234879;text-shadow:none}code[class*=language-]::mozselection,code[class*=language-]::selection,pre[class*=language-]::mozselection,pre[class*=language-]::selection{background:#234879;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{background:#161b22;margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-]{background:#343942;border-radius:.3em;color:#c9d1d9;padding:.1em .3em}pre[data-line]{position:relative}pre[class*=language-]>code[class*=language-]{position:relative;z-index:1}.line-highlight{background:#2f2a1e;box-shadow:inset 5px 0 0 #674c16;left:0;line-height:inherit;margin-top:1em;padding-bottom:inherit;padding-left:0;padding-right:0;padding-top:inherit;pointer-events:none;position:absolute;right:0;white-space:pre;z-index:0}.namespace{opacity:.7}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8b949e}.token.punctuation{color:#c9d1d9}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#79c0ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a5d6ff}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{background:#161b22;color:#a5d6ff}.token.atrule,.token.attr-value,.token.keyword{color:#a5d6ff}.token.function{color:#d2a8ff}.token.important,.token.regex,.token.variable{color:#a8daff}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style>
<style>pre[class*=language-].line-numbers{counter-reset:linenumber;padding-left:3.8em;position:relative}pre[class*=language-].line-numbers>code{position:relative;white-space:inherit}.line-numbers .line-numbers-rows{border-right:1px solid #999;font-size:100%;left:-3.8em;letter-spacing:-1px;pointer-events:none;position:absolute;top:0;-webkit-user-select:none;-moz-user-select:none;user-select:none;width:3em}.line-numbers-rows>span{counter-increment:linenumber;display:block}.line-numbers-rows>span:before{color:#999;content:counter(linenumber);display:block;padding-right:.8em;text-align:right}</style>
<style>.doc-header[data-v-9dc5fb00]{background:#fff;height:64px;transition-duration:.15s;transition-property:all;transition-timing-function:cubic-bezier(.4,0,.2,1)}.doc-header.scroll[data-v-9dc5fb00]{border-bottom:1px solid #e5e7eb;height:44px;position:fixed;width:100%;z-index:1000}.doc-header.scroll .inner_header[data-v-9dc5fb00]{padding:8px 20px 0}.doc-header.scroll .doc-title a[data-v-9dc5fb00]{padding:8px 15px 13px 0}.doc-header.scroll .link_nav[data-v-9dc5fb00]{padding:4px 10px 12px}.doc-header.scroll .btn_search[data-v-9dc5fb00]{background-position:top 6px right 16px;border-radius:1.071rem;padding:4px 48px 6px 31px}.doc-header .inner_header[data-v-9dc5fb00]{align-items:center;box-sizing:border-box;display:flex;justify-content:space-between;margin:0 auto;max-width:1280px;padding:20px 20px 8px}.doc-header .doc-title[data-v-9dc5fb00]{line-height:1.1}.doc-header .doc-title a[data-v-9dc5fb00]{display:inline-block;height:15px;padding:11px 15px 10px 0;vertical-align:top;width:99px}.doc-header .ico_logo[data-v-9dc5fb00]{height:100%;width:100%}.doc-header .doc-gnb[data-v-9dc5fb00],.doc-header .ico_logo[data-v-9dc5fb00]{display:inline-block;vertical-align:top}.doc-header .wrap_gnb.mo[data-v-9dc5fb00]{display:none}.doc-header .wrap_gnb.pc[data-v-9dc5fb00]{display:block}.doc-header .btn_search[data-v-9dc5fb00]{background-color:var(--strong-title);background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='17' height='17' fill='none'%3E%3Cpath fill='%23fff' fill-rule='evenodd' d='M6.748 12.316a.6.6 0 0 1 .016-.848L9.914 8.5l-3.15-2.968a.6.6 0 1 1 .832-.864l3.6 3.4a.6.6 0 0 1 0 .864l-3.6 3.4a.6.6 0 0 1-.848-.016' clip-rule='evenodd'/%3E%3C/svg%3E");background-position:top 10px right 16px;background-repeat:no-repeat;border-radius:1.29rem;color:#fff;letter-spacing:-.036rem;line-height:1.43;margin-left:25px;padding:8px 48px 8px 31px;vertical-align:top}.doc-header .list_menu[data-v-9dc5fb00]{display:flex}.doc-header .link_nav[data-v-9dc5fb00]{color:var(--category-gray);display:block;line-height:1.43;margin:0 15px;padding:8px 10px}.doc-header .link_nav[data-v-9dc5fb00]:hover{color:var(--strong-title)}.doc-header .link_nav.router-link-exact-active[data-v-9dc5fb00]{border-bottom:2px solid var(--strong-title);color:var(--strong-title)}.doc-header .btn_toggle[data-v-9dc5fb00]{background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' fill='currentColor' class='w-4 h-4 text-gray-800' viewBox='0 0 24 24'%3E%3Cpath fill-rule='evenodd' d='M4 5h16a1 1 0 0 1 0 2H4a1 1 0 1 1 0-2m0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2m0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2' class='astronav-open-icon astronav-toggle'/%3E%3C/svg%3E") no-repeat;height:24px;width:24px}.doc-header.open .btn_toggle[data-v-9dc5fb00]{background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='24' height='24' fill='currentColor' class='w-4 h-4 text-gray-800' viewBox='0 0 24 24'%3E%3Cpath fill-rule='evenodd' d='M18.278 16.864a1 1 0 0 1-1.414 1.414l-4.829-4.828-4.828 4.828a1 1 0 0 1-1.414-1.414l4.828-4.829-4.828-4.828a1 1 0 0 1 1.414-1.414l4.829 4.828 4.828-4.828a1 1 0 1 1 1.414 1.414l-4.828 4.829z' class='astronav-close-icon astronav-toggle' clip-rule='evenodd'/%3E%3C/svg%3E") no-repeat;padding:4px}@media screen and (max-width:1023px){.doc-header.open[data-v-9dc5fb00]{border-bottom:none}.doc-header.scroll.open .doc-gnb[data-v-9dc5fb00]{top:44px}.doc-header.scroll .btn_search[data-v-9dc5fb00]{background-position:top 7px left 6px;border-radius:50%;height:24px;padding:0;width:24px}.doc-header .doc-gnb[data-v-9dc5fb00]{background-color:#fff;left:0;position:absolute;right:0;top:64px;z-index:1000}.doc-header .list_menu[data-v-9dc5fb00]{border-bottom:1px solid #e5e7eb;flex-direction:column;padding-bottom:12px}.doc-header .list_menu .link_nav[data-v-9dc5fb00]{padding:8px 20px}.doc-header .list_menu .link_nav.router-link-exact-active[data-v-9dc5fb00]{border-bottom:none;font-weight:700}.doc-header .list_menu .link_nav.router-link-exact-active[data-v-9dc5fb00]:hover{color:var(--strong-title)}.doc-header .list_menu .link_nav[data-v-9dc5fb00]:hover{color:var(--category-gray)}.doc-header .wrap_gnb.mo[data-v-9dc5fb00]{align-items:center;display:flex}.doc-header .wrap_gnb.pc[data-v-9dc5fb00]{display:none}.doc-header .btn_search[data-v-9dc5fb00]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='25' height='25' fill='none'%3E%3Cg clip-path='url(%23a)'%3E%3Cpath fill='%23fff' d='M7.445 1.231a9.12 9.12 0 0 0-4.278 5.575 9.12 9.12 0 0 0 .918 6.968 9.21 9.21 0 0 0 7.958 4.592c1.034 0 2.06-.178 3.032-.52L19.205 25l2.945-1.7-4.13-7.153a9.1 9.1 0 0 0 2.885-4.588 9.12 9.12 0 0 0-.918-6.967A9.21 9.21 0 0 0 12.03 0a9.2 9.2 0 0 0-4.584 1.231zm9.598 5.061a5.74 5.74 0 0 1 .577 4.387 5.74 5.74 0 0 1-2.693 3.51 5.8 5.8 0 0 1-2.884.776 5.8 5.8 0 0 1-5.013-2.892 5.74 5.74 0 0 1-.578-4.386 5.74 5.74 0 0 1 2.694-3.51 5.8 5.8 0 0 1 2.883-.776 5.8 5.8 0 0 1 5.014 2.891'/%3E%3C/g%3E%3Cdefs%3E%3CclipPath id='a'%3E%3Cpath fill='%23fff' d='M0 0h25v25H0z'/%3E%3C/clipPath%3E%3C/defs%3E%3C/svg%3E");background-position:top 9px left 8px;background-repeat:no-repeat;background-size:50%;height:36px;margin-left:auto;margin-right:20px;padding:0;width:36px}}</style>
<style>.doc-footer[data-v-0fd47107]{color:var(--subTxt-gray);width:100%}.doc-footer .inner_footer[data-v-0fd47107]{background-color:var(--bg-footer);margin:0 auto;max-width:1280px;padding:55px 0}.doc-footer .section_sitemap[data-v-0fd47107]{display:grid;gap:64px;grid-template-columns:1fr 2fr;margin:0 auto;padding:0 20px 88px}.doc-footer .section_sitemap .tit_sitemap[data-v-0fd47107]{color:var(--logo-txt);font-size:1.29rem;font-weight:700;line-height:1.55}.doc-footer .section_sitemap .desc_sitemap[data-v-0fd47107]{color:var(--desc-bk);line-height:1.43;margin-top:1.14rem;max-width:500px}.doc-footer .section_sitemap .list_sns[data-v-0fd47107]{margin-top:1.14rem}.doc-footer .section_sitemap .list_sns li[data-v-0fd47107]{background-color:#e2e8f0;border-radius:4px;display:inline-block;height:24px;margin-right:12px;vertical-align:top;width:24px}.doc-footer .section_sitemap .list_sns .link_site[data-v-0fd47107]{box-sizing:border-box;display:block;font-size:0;height:100%;line-height:0;padding:4px}.doc-footer .section_sitemap .list_sns .link_site [class^=ico_][data-v-0fd47107]{display:block;height:16px;width:16px}.doc-footer .section_sitemap .list_sns .link_site .ico_youtube[data-v-0fd47107]{background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='16' height='16' fill='none' viewBox='0 0 16 16'%3E%3Cpath fill='%2364748B' d='M13.089 5.331q.01.175.008.35c0 3.55-2.702 7.64-7.64 7.64a7.6 7.6 0 0 1-4.124-1.206c.216.024.424.033.649.033a5.38 5.38 0 0 0 3.334-1.147 2.69 2.69 0 0 1-2.511-1.862c.166.024.332.041.507.041.24 0 .483-.033.707-.091a2.685 2.685 0 0 1-2.153-2.636V6.42c.358.2.773.324 1.213.34a2.68 2.68 0 0 1-1.197-2.235c0-.499.133-.956.365-1.355a7.64 7.64 0 0 0 5.538 2.81 3 3 0 0 1-.067-.615 2.684 2.684 0 0 1 2.685-2.686c.774 0 1.472.324 1.962.848a5.3 5.3 0 0 0 1.704-.648 2.68 2.68 0 0 1-1.18 1.48 5.4 5.4 0 0 0 1.546-.416 5.8 5.8 0 0 1-1.346 1.388'/%3E%3C/svg%3E") no-repeat}.doc-footer .section_sitemap .list_sns .link_site .ico_facebook[data-v-0fd47107]{background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='16' height='16' fill='none' viewBox='0 0 16 16'%3E%3Cpath fill='%2364748B' d='M8 1.335a6.666 6.666 0 0 0-1.04 13.252V9.928H5.265V8.001h1.693V6.532c0-1.672.996-2.594 2.518-2.594.73 0 1.493.13 1.493.13v1.64h-.843c-.826 0-1.085.514-1.085 1.041V8h1.847l-.295 1.928H9.042v4.658a6.666 6.666 0 0 0-1.041-13.25'/%3E%3C/svg%3E") no-repeat}.doc-footer .wrap_site[data-v-0fd47107]{display:flex;flex-grow:1;justify-content:space-between}.doc-footer .wrap_site .item_site[data-v-0fd47107]{color:var(--title-bk);font-weight:400;line-height:1.43;min-width:160px}.doc-footer .wrap_site .item_site h3[data-v-0fd47107]{display:block;margin-bottom:1.5rem}.doc-footer .wrap_site .link_site[data-v-0fd47107]{color:var(--subTxt-gray);display:block;margin:4px 0;padding:4px 0}.doc-footer .box_footer[data-v-0fd47107]{border-top:1px solid #e2e8f0;padding-top:2.36rem;text-align:center}.doc-footer .box_footer small[data-v-0fd47107]{display:block;line-height:1.43}.doc-footer .box_footer .wrap_footerlink[data-v-0fd47107]{font-size:.86rem;line-height:1.33;margin-top:.57rem}.doc-footer .box_footer .wrap_footerlink a[data-v-0fd47107]{color:var(--subTxt-gray)}.doc-footer .box_footer .wrap_footerlink a[data-v-0fd47107]:not(:first-of-type):before{background-color:var(--meta-data);border-radius:50%;content:"";display:inline-block;height:2px;line-height:1.43;margin:8px 10px;vertical-align:top;width:2px}@media screen and (max-width:1023px){.doc-footer[data-v-0fd47107]{padding:0}.doc-footer .inner_footer[data-v-0fd47107]{padding:30px 0}.doc-footer .section_sitemap[data-v-0fd47107]{display:block;padding-bottom:40px}.doc-footer .section_sitemap .desc_sitemap[data-v-0fd47107]{max-width:unset}.doc-footer .wrap_site[data-v-0fd47107]{flex-wrap:wrap;margin-left:0;margin-top:20px}.doc-footer .wrap_site .item_site[data-v-0fd47107]{margin-top:20px;width:50%}}@media screen and (max-width:767px){.doc-footer .wrap_site .item_site[data-v-0fd47107]{width:100%}}</style>
<style>.link_tag[data-v-b8b324b7]{border:1px solid;border-radius:40px;color:var(--strong-title);display:block;padding:.42rem .85rem;transition:all .3s ease 0s}.link_tag.type_white[data-v-b8b324b7]{border-color:#fff;color:#fff}.link_tag[data-v-b8b324b7]:hover{background-color:var(--strong-title);color:#fff}.link_tag:hover.type_white[data-v-b8b324b7]{background-color:#fff;color:var(--strong-title)}.router-link-active[data-v-b8b324b7]{background-color:var(--strong-title);color:#fff}.router-link-active.type_white[data-v-b8b324b7]{background-color:#fff;color:var(--strong-title)}@media screen and (max-width:1023px){.link_tag[data-v-b8b324b7]:hover{background:transparent;color:var(--strong-title)}.link_tag:hover.type_white[data-v-b8b324b7]{color:#fff}.link_tag.type_white[data-v-b8b324b7]:hover{background:var(--strong-title)}}</style>
<style>.list_tag[data-v-edff9524]{display:flex;flex-wrap:wrap;gap:1rem;margin-top:3.28rem}</style>
<style>.search_layer[data-v-bd8972db]{background:rgba(0,0,0,.5);bottom:0;font-size:13px;left:0;position:fixed;right:0;top:0;z-index:10000}.search_layer .inner_layer[data-v-bd8972db]{background-color:var(--strong-title);display:flex;flex-direction:column;padding:20px 0 36px;width:100%}.search_layer .layer_body[data-v-bd8972db]{box-sizing:border-box;margin:0 auto;max-width:1280px;padding:0 20px}.search_layer .area_search[data-v-bd8972db],.search_layer .layer_body[data-v-bd8972db]{align-items:flex-start;display:flex;justify-content:center;width:100%}.search_layer .link_logo[data-v-bd8972db]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='99' height='15' fill='none'%3E%3Cpath fill='%23fff' d='m2.554 11.175.006-3.267h.397l3.145-3.726h3.125L5.002 9.116h-.645zM.087 14V.91H2.81V14zm6.136 0-2.89-4.276L5.15 7.8 9.413 14zm7.14.185q-.94 0-1.675-.326a2.7 2.7 0 0 1-1.163-.978q-.422-.652-.422-1.623 0-.819.3-1.374.3-.557.819-.895a4 4 0 0 1 1.176-.512 9 9 0 0 1 1.393-.243q.857-.09 1.38-.166.525-.082.761-.243a.53.53 0 0 0 .237-.473v-.038q0-.607-.383-.94-.378-.332-1.074-.332-.735 0-1.17.326a1.5 1.5 0 0 0-.575.805l-2.519-.204q.192-.895.754-1.547a3.6 3.6 0 0 1 1.451-1.01q.895-.358 2.071-.358.819 0 1.567.192.754.192 1.335.594.588.403.927 1.036.339.626.339 1.502V14H16.31v-1.361h-.077a2.8 2.8 0 0 1-.633.811q-.396.346-.952.544-.557.19-1.285.191m.78-1.879q.6 0 1.06-.236.461-.244.723-.652a1.7 1.7 0 0 0 .262-.927V9.449a1.5 1.5 0 0 1-.351.153 6 6 0 0 1-.492.122 25 25 0 0 1-.55.096l-.499.07q-.48.07-.837.224a1.34 1.34 0 0 0-.556.415q-.199.256-.199.64 0 .555.403.85.41.287 1.036.287m9.329-1.131.006-3.267h.397l3.145-3.726h3.125L25.92 9.116h-.646zM21.005 14V.91h2.723V14zm6.136 0-2.89-4.276L26.068 7.8l4.264 6.2h-3.19zm7.14.185q-.94 0-1.675-.326a2.7 2.7 0 0 1-1.163-.978q-.422-.652-.422-1.623 0-.819.3-1.374.3-.557.819-.895a4 4 0 0 1 1.176-.512 9 9 0 0 1 1.393-.243q.856-.09 1.38-.166.525-.082.761-.243a.53.53 0 0 0 .237-.473v-.038q0-.607-.384-.94-.376-.332-1.073-.332-.735 0-1.17.326a1.5 1.5 0 0 0-.575.805l-2.519-.204q.193-.895.754-1.547a3.6 3.6 0 0 1 1.451-1.01q.895-.358 2.071-.358.819 0 1.566.192a4.1 4.1 0 0 1 1.336.594q.588.403.927 1.036.339.626.339 1.502V14h-2.582v-1.361h-.077a2.8 2.8 0 0 1-.633.811 2.9 2.9 0 0 1-.952.544q-.557.19-1.285.191m.78-1.879q.6 0 1.06-.236a1.9 1.9 0 0 0 .723-.652 1.7 1.7 0 0 0 .262-.927V9.449a1.5 1.5 0 0 1-.351.153 6 6 0 0 1-.493.122q-.274.051-.55.096l-.498.07q-.48.07-.837.224a1.33 1.33 0 0 0-.556.415q-.198.256-.198.64 0 .555.402.85.41.287 1.036.287m11.298 1.886q-1.49 0-2.576-.633a4.33 4.33 0 0 1-1.669-1.777q-.588-1.144-.588-2.653 0-1.52.588-2.659a4.3 4.3 0 0 1 1.669-1.777q1.086-.639 2.576-.639t2.57.64a4.27 4.27 0 0 1 1.674 1.776q.588 1.138.588 2.66 0 1.508-.588 2.652a4.3 4.3 0 0 1-1.675 1.777q-1.08.633-2.57.633zm.012-2.11q.678 0 1.132-.383.453-.39.684-1.061.236-.672.236-1.528 0-.855-.236-1.528-.231-.67-.684-1.06t-1.132-.39q-.684 0-1.15.39-.461.39-.697 1.06-.23.672-.23 1.528t.23 1.528q.237.67.697 1.06.467.384 1.15.384m20.145-7.9v2.045h-5.913V4.182zm-4.57-2.352h2.723v9.153q0 .377.115.588a.64.64 0 0 0 .32.288q.21.083.485.083.192 0 .384-.032l.294-.058.428 2.027a8 8 0 0 1-.575.147 4.6 4.6 0 0 1-.902.108q-.984.039-1.726-.262-.734-.3-1.144-.933t-.402-1.598zm10.713 12.362q-1.515 0-2.608-.614a4.2 4.2 0 0 1-1.675-1.751q-.588-1.138-.588-2.691 0-1.515.588-2.66a4.35 4.35 0 0 1 1.656-1.783q1.074-.639 2.518-.639.971 0 1.809.313a4 4 0 0 1 1.47.927q.633.62.985 1.56.351.932.351 2.186v.748h-8.29V8.1h5.727q0-.588-.256-1.042a1.83 1.83 0 0 0-.71-.71 2 2 0 0 0-1.041-.261q-.62 0-1.1.287a2 2 0 0 0-.741.76q-.269.474-.275 1.056v1.604q0 .729.269 1.26.274.53.773.817.498.288 1.183.288.453 0 .83-.128.378-.128.646-.383c.268-.255.315-.38.41-.627l2.518.166a3.44 3.44 0 0 1-.787 1.586q-.588.671-1.52 1.048-.928.37-2.142.37zm10.72 0q-1.51 0-2.596-.64a4.3 4.3 0 0 1-1.662-1.79q-.575-1.143-.575-2.633 0-1.508.581-2.646A4.3 4.3 0 0 1 80.796 4.7q1.08-.645 2.57-.646 1.284 0 2.25.467a3.76 3.76 0 0 1 1.527 1.31q.563.844.62 1.981h-2.57q-.108-.735-.575-1.182-.46-.454-1.208-.454-.633 0-1.106.345-.466.339-.728.991t-.262 1.579q0 .94.255 1.598.262.658.735 1.004.474.345 1.106.345a1.8 1.8 0 0 0 .838-.192q.376-.192.62-.556.249-.371.326-.889h2.57q-.065 1.125-.614 1.982a3.7 3.7 0 0 1-1.503 1.33q-.958.479-2.269.479zm8.85-5.868V14h-2.722V.91h2.646v5.004h.115a2.78 2.78 0 0 1 1.074-1.361q.741-.5 1.86-.499 1.023 0 1.783.447a3 3 0 0 1 1.19 1.272q.427.825.421 1.976V14h-2.723V8.234q.005-.908-.46-1.412-.46-.505-1.291-.505-.557 0-.985.236a1.68 1.68 0 0 0-.665.69q-.236.448-.242 1.08z'/%3E%3C/svg%3E");background-position:50%;background-repeat:no-repeat;display:inline-block;flex-shrink:0;height:28px;padding:4px 0;vertical-align:top;width:110px}.search_layer .wrap_input[data-v-bd8972db]{flex-grow:1;margin:0 63px 0 89px;width:100%}.search_layer .box_input[data-v-bd8972db]{background-color:#fff;background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='25' height='25' fill='none'%3E%3Cg clip-path='url(%23a)'%3E%3Cpath fill='%235445DE' d='M7.445 1.231a9.12 9.12 0 0 0-4.278 5.575 9.12 9.12 0 0 0 .918 6.968 9.21 9.21 0 0 0 7.958 4.592c1.034 0 2.06-.178 3.032-.52L19.205 25l2.945-1.7-4.13-7.153a9.1 9.1 0 0 0 2.885-4.588 9.12 9.12 0 0 0-.918-6.967A9.21 9.21 0 0 0 12.03 0a9.2 9.2 0 0 0-4.584 1.231zm9.598 5.061a5.74 5.74 0 0 1 .577 4.387 5.74 5.74 0 0 1-2.693 3.51 5.8 5.8 0 0 1-2.884.776 5.8 5.8 0 0 1-5.013-2.892 5.74 5.74 0 0 1-.578-4.386 5.74 5.74 0 0 1 2.694-3.51 5.8 5.8 0 0 1 2.883-.776 5.8 5.8 0 0 1 5.014 2.891'/%3E%3C/g%3E%3Cdefs%3E%3CclipPath id='a'%3E%3Cpath fill='%23fff' d='M0 0h25v25H0z'/%3E%3C/clipPath%3E%3C/defs%3E%3C/svg%3E");background-position:top 7px left 8px;background-repeat:no-repeat;border-radius:1.286rem;padding:7px 8px 8px 49px;position:relative}.search_layer .box_input input[data-v-bd8972db]{-moz-appearance:none;appearance:none;-webkit-appearance:none;background:transparent;border:0;color:#333;font-size:.929rem;outline:none;width:100%}.search_layer .box_input input[data-v-bd8972db]::-moz-placeholder{color:#333}.search_layer .box_input input[data-v-bd8972db]::placeholder{color:#333}.search_layer .box_input .btn_close[data-v-bd8972db]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' class='ico_close' style='width:18px;height:18px;stroke:%23000' viewBox='0 0 28 28'%3E%3Cg fill='none' fill-rule='evenodd' stroke-linecap='square' stroke-width='1.6'%3E%3Cpath d='m6 5.5 16.5 17M23 5.5l-16.5 17'/%3E%3C/g%3E%3C/svg%3E");background-position:50% 50%;background-repeat:no-repeat;background-size:18px 18px;height:36px;position:absolute;right:0;top:0;width:36px}.search_layer .btn_search[data-v-bd8972db]{background-color:#fff;background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='17' height='17' fill='none'%3E%3Cpath fill='%234F46E5' fill-rule='evenodd' d='M6.748 12.316a.6.6 0 0 1 .016-.848L9.914 8.5l-3.15-2.968a.6.6 0 1 1 .832-.864l3.6 3.4a.6.6 0 0 1 0 .864l-3.6 3.4a.6.6 0 0 1-.848-.016' clip-rule='evenodd'/%3E%3C/svg%3E");background-position:top 10px right 16px;background-repeat:no-repeat;border-radius:1.29rem;color:var(--strong-title);flex-grow:0;letter-spacing:-.036rem;line-height:1.43;padding:8px 48px 8px 31px;vertical-align:top}.search_layer .list_tag[data-v-bd8972db]{max-height:134px;overflow:hidden}@media screen and (max-width:1023px){.search_layer .layer_body[data-v-bd8972db]{flex-direction:column}.search_layer .area_search[data-v-bd8972db]{margin-top:10px}.search_layer .list_tag[data-v-bd8972db]{max-height:280px}.search_layer .wrap_input[data-v-bd8972db]{margin-left:0;margin-right:20px}.search_layer .box_input input[data-v-bd8972db]{font-size:16px}.search_layer .box_input .btn_close[data-v-bd8972db]{top:1px}.search_layer .btn_search[data-v-bd8972db]{background-image:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='25' height='25' fill='none'%3E%3Cg clip-path='url(%23a)'%3E%3Cpath fill='%235445DE' d='M7.445 1.231a9.12 9.12 0 0 0-4.278 5.575 9.12 9.12 0 0 0 .918 6.968 9.21 9.21 0 0 0 7.958 4.592c1.034 0 2.06-.178 3.032-.52L19.205 25l2.945-1.7-4.13-7.153a9.1 9.1 0 0 0 2.885-4.588 9.12 9.12 0 0 0-.918-6.967A9.21 9.21 0 0 0 12.03 0a9.2 9.2 0 0 0-4.584 1.231zm9.598 5.061a5.74 5.74 0 0 1 .577 4.387 5.74 5.74 0 0 1-2.693 3.51 5.8 5.8 0 0 1-2.884.776 5.8 5.8 0 0 1-5.013-2.892 5.74 5.74 0 0 1-.578-4.386 5.74 5.74 0 0 1 2.694-3.51 5.8 5.8 0 0 1 2.883-.776 5.8 5.8 0 0 1 5.014 2.891'/%3E%3C/g%3E%3Cdefs%3E%3CclipPath id='a'%3E%3Cpath fill='%23fff' d='M0 0h25v25H0z'/%3E%3C/clipPath%3E%3C/defs%3E%3C/svg%3E");background-position:top 9px left 8px;background-repeat:no-repeat;background-size:50%;margin-left:auto;padding:18px}}</style>
<style>.container-doc[data-v-b20c6296]{display:flex;flex-direction:column;min-height:100vh}.doc-header.scroll+.doc-main[data-v-b20c6296]{padding-top:194px}.doc-main[data-v-b20c6296]{align-items:center;display:flex;flex-grow:1;justify-content:center;padding:214px 0 150px}.content-error[data-v-b20c6296]{text-align:center}.content-error .tit_error[data-v-b20c6296]{background:linear-gradient(180deg,#333,#999);-webkit-background-clip:text;background-clip:text;color:transparent;display:block;font-size:9.14rem;font-weight:700;line-height:1.1;padding-bottom:1.14rem}.content-error .desc_error[data-v-b20c6296]{color:var(--desc-bk);display:block;font-size:1.72rem;font-weight:400;line-height:1.33}.content-error .btn_home[data-v-b20c6296]{border:2px solid #6366f1;border-radius:1.72rem;color:var(--strong-title);font-size:1.14rem;margin-top:2.14rem;padding:.72rem 2rem}@media screen and (max-width:768px){.content-error .tit_error[data-v-b20c6296]{font-size:7rem}.content-error .desc_error[data-v-b20c6296]{font-size:1.5rem}}</style>
<style>.container-doc[data-v-3a9b2a8a]{display:flex;flex-direction:column;min-height:100vh}.doc-header.scroll+.doc-main[data-v-3a9b2a8a]{padding-top:44px}.doc-main[data-v-3a9b2a8a]{box-sizing:border-box;flex-grow:1;margin:0 auto;max-width:1280px;padding:0 20px;width:100%}</style>
<style>.comm_loading[data-v-cddd4cdd]{background-color:transparent;bottom:0;left:0;position:fixed;right:0;top:0;z-index:10000}.comm_loading span[data-v-cddd4cdd]{background:rgba(0,0,0,.8);border-radius:8px;height:64px;left:50%;line-height:1px;margin:-32px 0 0 -32px;position:absolute;text-indent:-9999px;top:50%;width:64px}.comm_loading span[data-v-cddd4cdd]:after{animation:spin-cddd4cdd 1.5s linear infinite;border:3px solid #fff;border-radius:12px;border-top-color:transparent;box-sizing:border-box;content:"";height:24px;left:20px;position:absolute;top:20px;width:24px}@keyframes spin-cddd4cdd{0%{transform:rotate(0deg)}to{transform:rotate(1turn)}}</style>
<style>.content-article[data-v-72a79301]{padding:69px 0 88px}.wrap_tit[data-v-72a79301]{margin:0 auto;max-width:800px;text-align:center}.list_cate li[data-v-72a79301]{color:var(--sub-title);display:inline-block;font-weight:400;line-height:1.43;vertical-align:top}.list_cate li+li[data-v-72a79301]:before{content:" & "}.tit_post[data-v-72a79301]{display:block;font-size:2.5rem;font-weight:700;line-height:1.25;padding-top:.5rem}.info_post[data-v-72a79301]{display:flex;flex-wrap:wrap;justify-content:center;line-height:1.43;padding-top:.86rem}.info_post>a+span[data-v-72a79301]{color:#94a3b8}.info_post>a+span[data-v-72a79301]:before{background-color:var(--meta-data);border-radius:50%;content:"";display:inline-block;height:4px;line-height:20px;margin:8px 10px;vertical-align:top;width:4px}.info_post>a[data-v-72a79301]{color:#94a3b8}.info_post>a+a[data-v-72a79301]:before{content:"/";display:inline-block;margin:0 4px;vertical-align:top}.list_tag[data-v-72a79301]{display:flex;flex-wrap:wrap}.list_tag[data-v-72a79301]:before{background-color:var(--meta-data);border-radius:50%;content:"";display:inline-block;height:4px;line-height:20px;margin:8px 10px;vertical-align:top;width:4px}.list_tag li+li[data-v-72a79301]{padding-left:12px}.link_tag[data-v-72a79301]{color:var(--descTxt-gray)}.link_tag[data-v-72a79301]:before{content:"#"}.wrap_content[data-v-72a79301]{display:flex;gap:25px;margin:0 auto;max-width:800px;position:relative}.wrap_content .inner_content[data-v-72a79301]{flex:1;width:100%}.wrap_content .box_author[data-v-72a79301],.wrap_content .preview[data-v-72a79301],.wrap_content aside[data-v-72a79301]{margin-top:50px}.wrap_content .box_author[data-v-72a79301]{margin-left:-255px;width:230px}.wrap_content .info_author[data-v-72a79301]{display:grid;grid-template-columns:64px 1fr;grid-template-rows:auto 1fr}.wrap_content .info_author+.info_author[data-v-72a79301]{border-top:1px solid #eee;margin-top:20px;padding-top:20px}.wrap_content .thumb_author[data-v-72a79301]{border-radius:50%;height:64px;overflow:hidden;width:64px}.wrap_content .thumb_author img[data-v-72a79301]{height:100%;-o-object-fit:cover;object-fit:cover;width:100%}.wrap_content .thumb_author+.tit_author[data-v-72a79301]{margin-top:8px}.wrap_content .inner_author[data-v-72a79301]{overflow:hidden;text-align:right}.wrap_content .tit_author[data-v-72a79301]{display:block;font-weight:700;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;word-break:break-all}.wrap_content .desc_author[data-v-72a79301]{grid-column:span 2;margin-top:8px}.wrap_content .link_author[data-v-72a79301]{background-color:#d9d9d9;border-radius:5px;display:inline-block;font-size:.88rem;margin-top:6px;padding:4px 8px 4px 10px}.box_btn[data-v-72a79301]{display:flex;justify-content:center;margin:86px auto 77px}.box_btn .btn_back+.btn_back[data-v-72a79301]{margin-left:10px}.box_giscus[data-v-72a79301]{margin:0 auto;max-width:800px}.cont_other[data-v-72a79301]{background:#f3f4f6;border:1px solid #a3a3a3;border-radius:5px;display:flex;justify-content:space-between;padding:10px}.cont_other a[data-v-72a79301]{display:flex;flex:1}.cont_other a+a[data-v-72a79301]{padding-left:21px;position:relative}.cont_other a+a[data-v-72a79301]:before{background-color:#a3a3a3;bottom:0;content:"";left:10px;position:absolute;top:0;width:1px}.cont_other .box_cont[data-v-72a79301]{flex:1;padding-top:4px}.cont_other .box_cont span[data-v-72a79301]{color:#666}.cont_other .box_cont div[data-v-72a79301]{padding-top:4px}.link_next[data-v-72a79301]:after,.link_prev[data-v-72a79301]:before{background-size:30px 30px;background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' width='30' height='30' fill='none' viewBox='0 0 30 30'%3E%3Cpath stroke='%23A3A3A3' stroke-linecap='round' stroke-linejoin='round' stroke-width='1.873' d='M18.465 19.994 13.47 15l4.994-4.994'/%3E%3C/svg%3E") no-repeat;content:"";display:block;flex:none;height:30px;width:30px}.link_next[data-v-72a79301]:after{transform:rotate(-180deg)}@media screen and (max-width:1310px){.box_author[data-v-72a79301]{display:none}}@media screen and (max-width:768px){.list_tag[data-v-72a79301]{justify-content:center;margin-top:4px;width:100%}.list_tag[data-v-72a79301]:before{display:none}.box_btn[data-v-72a79301]{align-items:center;flex-direction:column}.box_btn .btn_back+.btn_back[data-v-72a79301]{margin:10px 0 0}.cont_other[data-v-72a79301]{flex-direction:column}.cont_other a+a[data-v-72a79301]{padding-top:21px}.cont_other a+a[data-v-72a79301]:before{background-color:#a3a3a3;height:1px;left:0;right:0;top:10px;width:100%}}</style>
<style>aside{background:#fff;box-sizing:border-box;height:100%;position:absolute;right:-425px;top:0;width:400px}aside li button{border-radius:8px;color:#545b63;display:block;line-height:22px;padding:5px 8px;text-align:left;width:100%}aside .list_tit{left:0;max-height:calc(100vh - 100px);overflow-y:auto;padding:0 20px 50px;position:sticky;top:50px}aside .list_tit>li.active>button{background:#edeff1}aside .list_tit .item_sub{border-left:3px solid #dddddf;margin-left:20px;padding-left:17px}aside .list_tit .item_sub.active>button{background:#d1d8dc}@media screen and (max-width:1310px){aside{display:none}}</style>
<style>.comm_btn[data-v-c602fe17]{background-color:var(--paging-gray);border-radius:.43rem;display:block;font-size:1.14rem;padding:.71rem 1.43rem;width:-moz-fit-content;width:fit-content}</style>
<link rel="stylesheet" href="/_nuxt/entry.2RRRXIkF.css" crossorigin>
<link rel="stylesheet" href="/_nuxt/PostPage.85EBTB_V.css" crossorigin>
<link rel="stylesheet" href="/_nuxt/Button.DNoQo9Pi.css" crossorigin>
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/CTp7hcOz.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/Ndf7c_b4.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/wa6c2AYN.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/USKnHnfB.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/DEBxdRof.js">
<link rel="modulepreload" as="script" crossorigin href="/_nuxt/BQYTav1U.js">
<meta name="robots" content="max-image-preview:large">
<meta property="og:locale" content="ko_KR">
<meta property="og:site_name" content="tech.kakao.com">
<meta property="article:publisher" content="https://www.facebook.com/kakaotech/">
<meta name="twitter:card" content="summary_large_image">
<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
<link rel="icon" type="image/x-icon" href="https://www.kakaocorp.com/page/favicon.ico">
<noscript>이 페이지를 실행하려면 자바스크립트를 사용해야 합니다.</noscript>
<meta property="og:title" content="이미지와 음성을 아우르는 카카오의 멀티모달 언어모델 Kanana-o 알아보기 - tech.kakao.com">
<meta property="og:url" content="https://tech.kakao.com/posts/702">
<meta property="og:type" content="article">
<meta property="og:description" content="안녕하세요, 카카오의 AI 모델 개발을 담당하는 카나나(Kanana) 조직의 Ed...">
<meta property="og:image" content="https://img1.kakaocdn.net/thumb/U896x0/?fname=https%3A%2F%2Ft1.kakaocdn.net%2Fkakao_tech%2Fimage%2F86040109019600001.png">
<meta property="og:image:url" content="https://img1.kakaocdn.net/thumb/U896x0/?fname=https%3A%2F%2Ft1.kakaocdn.net%2Fkakao_tech%2Fimage%2F86040109019600001.png">
<meta name="twitter:title" content="이미지와 음성을 아우르는 카카오의 멀티모달 언어모델 Kanana-o 알아보기 - tech.kakao.com">
<meta name="twitter:url" content="https://tech.kakao.com/posts/702">
<meta name="twitter:description" content="안녕하세요, 카카오의 AI 모델 개발을 담당하는 카나나(Kanana) 조직의 Ed...">
<meta name="twitter:image" content="https://img1.kakaocdn.net/thumb/U896x0/?fname=https%3A%2F%2Ft1.kakaocdn.net%2Fkakao_tech%2Fimage%2F86040109019600001.png">
<script type="module" src="/_nuxt/CTp7hcOz.js" crossorigin></script>
<script id="unhead:payload" type="application/json">{"title":"tech.kakao.com - 카카오테크, 미래의 문턱을 낮추는 기술"}</script></head><body  id="mainContent" class="line-numbers"><div id="__nuxt"><!--[--><div class="direct-link" data-v-3a9b2a8a><a href="#mainContent" data-v-3a9b2a8a>본문 바로가기</a><a href="#gnbContent" data-v-3a9b2a8a>메뉴 바로가기</a></div><div class="container-doc" aria-hidden="false" data-v-3a9b2a8a><header class="doc-header" data-v-3a9b2a8a data-v-9dc5fb00><div class="inner_header" data-v-9dc5fb00><h1 class="doc-title" data-v-9dc5fb00><a href="/" class="" data-v-9dc5fb00><img src="https://t1.kakaocdn.net/kakao_tech/resources/static/ico_logo.png" class="ico_logo" alt="kakao tech" data-v-9dc5fb00></a></h1><div class="wrap_gnb mo" data-v-9dc5fb00><button type="button" class="btn_search" data-v-9dc5fb00><strong class="screen_out" data-v-9dc5fb00>검색하기</strong></button><button type="button" class="btn_toggle" aria-expanded="false" data-v-9dc5fb00><span class="ir_pm" data-v-9dc5fb00>메뉴 열기</span></button><!----></div><div class="wrap_gnb pc" data-v-9dc5fb00><nav id="gnbContent" class="doc-gnb" data-v-9dc5fb00><h2 class="screen_out" data-v-9dc5fb00>테크 카카오 메뉴</h2><ul class="list_menu" data-v-9dc5fb00><!--[--><li data-v-9dc5fb00><a href="/blog" class="link_nav" data-v-9dc5fb00>Blog</a></li><li data-v-9dc5fb00><a href="/events" class="link_nav" data-v-9dc5fb00>Events</a></li><li data-v-9dc5fb00><a href="/careers" class="link_nav" data-v-9dc5fb00>Careers</a></li><li data-v-9dc5fb00><a href="https://developers.kakao.com/" class="link_nav" target="_blank" data-v-9dc5fb00>Kakao Developers<span class="screen_out" data-v-9dc5fb00>새창열림</span></a></li><!--]--></ul></nav><button type="button" class="btn_search" data-v-9dc5fb00> Search <strong class="screen_out" data-v-9dc5fb00>검색하기</strong></button></div></div></header><main class="doc-main" data-v-3a9b2a8a><!--[--><article class="content-article" data-v-72a79301><div class="wrap_tit" data-v-72a79301><ul class="list_cate" data-v-72a79301><span data-v-72a79301></span></ul><h1 class="daum-wm-title tit_post" data-v-72a79301>이미지와 음성을 아우르는 카카오의 멀티모달 언어모델 Kanana-o 알아보기</h1><div class="info_post" data-v-72a79301><span data-v-72a79301></span></div></div><div class="wrap_content" data-v-72a79301><div class="box_author" data-v-72a79301><!--[--><div class="info_author" data-v-72a79301><div class="thumb_author" data-v-72a79301><img src="https://t1.kakaocdn.net/kakao_tech/author/85f44fe3019600001.jpg" alt="edwin.ai의 프로필 사진" data-v-72a79301></div><div class="inner_author" data-v-72a79301><span class="tit_author" data-v-72a79301>edwin.ai</span><a href="/author/edwin.ai" class="link_author" data-v-72a79301>View →</a></div><p class="desc_author" data-v-72a79301></p></div><div class="info_author" data-v-72a79301><div class="thumb_author" data-v-72a79301><img src="https://t1.kakaocdn.net/kakao_tech/author/85f4cc95019600001.jpg" alt="james.e의 프로필 사진" data-v-72a79301></div><div class="inner_author" data-v-72a79301><span class="tit_author" data-v-72a79301>james.e</span><a href="/author/james.e" class="link_author" data-v-72a79301>View →</a></div><p class="desc_author" data-v-72a79301></p></div><!--]--></div><aside data-v-72a79301><ul class="list_tit"><!--[--><!--]--></ul></aside><div class="inner_content" data-v-72a79301><div class="daum-wm-content preview" data-v-72a79301></div><div class="box_btn" data-v-72a79301><!--[--><a href="/blog" class="comm_btn btn_back" data-v-72a79301 data-v-c602fe17><!--[-->← Back to Blog<!--]--></a><!--]--></div><span data-v-72a79301></span><div class="cont_other" data-v-72a79301><a href="/posts/701" class="link_prev" data-v-72a79301><div class="box_cont" data-v-72a79301><span data-v-72a79301>이전 글</span><div data-v-72a79301>AI야, 문서 좀 대신 써 줘 - 2. 쪽지 시험</div></div></a><!----></div></div></div></article><!--]--></main><footer class="doc-footer" data-v-3a9b2a8a data-v-0fd47107><div class="inner_footer" data-v-0fd47107><section class="section_sitemap" data-v-0fd47107><h2 class="screen_out" data-v-0fd47107>카카오테크 사이트맵</h2><div data-v-0fd47107><strong class="tit_sitemap" data-v-0fd47107>kakao tech</strong><p class="desc_sitemap" data-v-0fd47107> Kakao lowers the barrier to the future, and brings tomorrow&#39;s technology into your life </p></div><div class="wrap_site" data-v-0fd47107><!--[--><div class="item_site" data-v-0fd47107><h3 data-v-0fd47107>Tech Sites</h3><ul data-v-0fd47107><!--[--><li data-v-0fd47107><a href="https://developers.kakao.com/" target="_blank" class="link_site" data-v-0fd47107>Kakao Developers<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://github.com/kakao" target="_blank" class="link_site" data-v-0fd47107>Kakao OpenSource<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://apis.map.kakao.com/" target="_blank" class="link_site" data-v-0fd47107>Kakao Maps API<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://olive.kakao.com/intro" target="_blank" class="link_site" data-v-0fd47107>Kakao Olive Platform<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><!--]--></ul></div><div class="item_site" data-v-0fd47107><h3 data-v-0fd47107>Channels</h3><ul data-v-0fd47107><!--[--><li data-v-0fd47107><a href="https://www.youtube.com/@kakaotech" target="_blank" class="link_site" data-v-0fd47107>Youtube<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://www.facebook.com/kakaotech" target="_blank" class="link_site" data-v-0fd47107>Facebook<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://pf.kakao.com/_qmkxcs" target="_blank" class="link_site" data-v-0fd47107>Talk Channel<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><!--]--></ul></div><div class="item_site" data-v-0fd47107><h3 data-v-0fd47107>Events</h3><ul data-v-0fd47107><!--[--><li data-v-0fd47107><a href="https://if.kakao.com/" target="_blank" class="link_site" data-v-0fd47107>If Kakao Conf<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://festa.io/hosts/388" target="_blank" class="link_site" data-v-0fd47107>Kakao Tech Meet<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><!--]--></ul></div><div class="item_site" data-v-0fd47107><h3 data-v-0fd47107>Family Sites</h3><ul data-v-0fd47107><!--[--><li data-v-0fd47107><a href="https://www.kakaocorp.com/page/" target="_blank" class="link_site" data-v-0fd47107>Kakao Corp<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://careers.kakao.com/index" target="_blank" class="link_site" data-v-0fd47107>Kakao Career<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><li data-v-0fd47107><a href="https://www.kakao.com/ko/privacy" target="_blank" class="link_site" data-v-0fd47107>Kakao Privacy<span class="screen_out" data-v-0fd47107>새창열림</span></a></li><!--]--></ul></div><!--]--></div></section><div class="box_footer" data-v-0fd47107><small data-v-0fd47107>Copyright © Kakao Corp. All Rights Reserved.</small><div class="wrap_footerlink" data-v-0fd47107><a href="https://www.kakao.com/policy/oppolicy?lang=ko" target="_blank" data-v-0fd47107>Terms <span class="screen_out" data-v-0fd47107>새창열림</span></a><a href="https://www.kakao.com/policy/privacy?lang=ko" target="_blank" data-v-0fd47107>Privacy <span class="screen_out" data-v-0fd47107>새창열림</span></a></div></div></div></footer></div><a href="#mainContent" aria-hidden="false" data-v-3a9b2a8a><span class="screen_out" data-v-3a9b2a8a>최상위로 이동</span></a><span data-v-3a9b2a8a data-v-cddd4cdd></span><section class="search_layer" aria-hidden="true" style="display:none;" data-v-3a9b2a8a data-v-bd8972db><div class="inner_layer" data-v-bd8972db><div class="layer_head" data-v-bd8972db><h2 class="ir_pm" data-v-bd8972db>콘텐츠 검색</h2></div><div class="layer_body" data-v-bd8972db><h2 class="ir_pm" data-v-bd8972db>콘텐츠 검색</h2><a href="/" class="link_logo" data-v-bd8972db><span class="screen_out" data-v-bd8972db>메인페이지로 이동</span></a><div class="area_search" data-v-bd8972db><div class="wrap_input" data-v-bd8972db><div class="box_input" data-v-bd8972db><label for="inpSearch" class="lab_search" data-v-bd8972db><span class="screen_out" data-v-bd8972db>검색어 입력</span></label><input id="inpSearch" name="inpSearch" type="text" placeholder="검색어를 입력해주세요." autocomplete="off" data-v-bd8972db><button type="button" class="btn_close" data-v-bd8972db><span class="screen_out" data-v-bd8972db>검색창 닫기</span></button></div><div class="box_tag" data-v-bd8972db><ul class="list_tag" data-v-bd8972db data-v-edff9524><!--[--><!--]--></ul></div></div><button type="button" class="btn_search" data-v-bd8972db>Search <strong class="screen_out" data-v-bd8972db>검색하기</strong></button></div></div></div></section><!--]--></div><div id="teleports"></div><script type="application/json" data-nuxt-data="nuxt-app" data-ssr="true" id="__NUXT_DATA__">[["ShallowReactive",1],{"data":2,"state":36,"once":38,"_errors":39,"serverRendered":41,"path":42,"pinia":43},["ShallowReactive",3],{"xovt2v3E6R":4},{"id":5,"title":6,"releaseDate":7,"releaseDateTime":8,"categories":9,"author":12,"authors":13,"thumbnailUri":22,"tags":23,"content":30,"components":31,"prevPostTitleResponse":33,"nextPostTitleResponse":12},702,"이미지와 음성을 아우르는 카카오의 멀티모달 언어모델 Kanana-o 알아보기","2025.05.01","2025.05.01 08:00:00",[10],{"code":11,"name":11},"blog",null,[14,18],{"name":15,"description":16,"profile":17},"edwin.ai","안녕하세요, 카나나 조직에서 멀티모달 언어모델을 연구/개발하는 Edwin 입니다. 사용자에게 실질적인 편의와 다양한 가치를 제공하는 이로운 기술을 추구하며, 카나나가 글로벌 경쟁력을 갖춘 모델이 될 수 있도록 노력하고 있습니다.","https://t1.kakaocdn.net/kakao_tech/author/85f44fe3019600001.jpg",{"name":19,"description":20,"profile":21},"james.e","카나나 조직에서 멀티모달 언어모델을 연구/개발하는 James 입니다. 다양한 분야의 문제들을 데이터와 AI 기술로 풀어내기 위해 노력하고 있습니다.","https://t1.kakaocdn.net/kakao_tech/author/85f4cc95019600001.jpg","https://t1.kakaocdn.net/kakao_tech/image/86040109019600001.png",[24,26,28],{"name":25},"ai",{"name":27},"kanana",{"name":29},"Kananamodel","\u003Cp>안녕하세요, 카카오의 AI 모델 개발을 담당하는 카나나(Kanana) 조직의 \u003Cstrong>Edwin(강우영)\u003C/strong>, \u003Cstrong>James(이재명)\u003C/strong> 입니다. 저희 팀에서는 다양한 모달리티 데이터를 처리할 수 있는 멀티모달 언어모델을 중점적으로 개발하고 있습니다.\u003C/p>\n\u003Cp>지난해 12월, \u003Ca href=\"https://tech.kakao.com/posts/667\">이미지를 이해할 수 있는 멀티모달 언어모델인 Kanana-v\u003C/a>를 소개해 드린 바 있는데요. 이번 글에서는 텍스트와 오디오를 이해하는 오디오 언어모델인 \u003Cstrong>Kanana-a\u003C/strong>와 텍스트, 이미지, 오디오 모두를 이해하는 \u003Cstrong>Kanana-o\u003C/strong>를 소개합니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85f6cd34019600001.jpg\" alt=\"그림 1. 카카오의 멀티모달 언어모델 라인업\">\u003C/p>\n\u003Cp>Kanana-o는 Kanana-v와 Kanana-a를 모델 병합(Model Merging) 기법으로 결합하여 학습 효율을 극대화했습니다. 또한, 자체 제작한 이미지-오디오 통합 모달리티 데이터를 포함해 지금까지 쌓아온 학습 노하우를 바탕으로, 단기간에 다양한 한국어 및 영어 벤치마크에서 글로벌 경쟁력을 입증했습니다.\u003C/p>\n\u003Cp>이번 글에서는 이러한 결과를 만들어내기까지 저희가 마주했던 도전 과제들과, 이를 극복하기 위해 고민하고 노력했던 과정을 자세히 소개하고자 합니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/86c8e62c019600001.png\" alt=\"그림 2. Kanana-o와 글로벌 경쟁모델들의 음성 및 통합 모달리티 벤치마크 성능 비교\">\u003C/p>\n\u003Cp>특히, 아직 소개해드리지 못헀던 Kanana-a에 대해 먼저 자세하게 소개하고, 이를 Kanana-v와 결합하여 Kanana-o를 만든 과정을 설명드리겠습니다. 이어서 성능에 대한 자세한 정량 수치와 다양한 활용 예시들을 보여드리며 글을 마무리하도록 하겠습니다.\u003C/p>\n\u003Ch2 id=\"카카오의-음성-이해-모델-kanana-a\">카카오의 음성 이해 모델: Kanana-a\u003C/h2>\n\u003Cp>사람과 기계가 소통하는 가장 자연스러운 방식은 ‘말하기’라고 할 수 있습니다. 음성은 텍스트보다 입력 속도가 빠르고, 시각적 주의를 요구하지 않으며, 몰입감 있는 소통 수단으로서도 강력합니다. 특히 운전 중, 운동 중, AR/VR 기기처럼 손이나 눈이 자유롭지 않은 환경에서는 텍스트보다 훨씬 직관적인 인터페이스가 됩니다.\u003C/p>\n\u003Cp>그뿐만 아니라, 음성은 단순한 정보 전달을 넘어 감정과 뉘앙스까지 담을 수 있는 소통의 수단입니다. 우리는 누군가의 \u003Cstrong>말투, 속도, 억양, 리듬, 배경 소리\u003C/strong>까지 종합해 의미를 해석하고, 그에 맞는 방식으로 반응합니다.\u003C/p>\n\u003Cp>반면, 텍스트 중심 LLM은 이 모든 \u003Cstrong>비 언어적 정보\u003C/strong>(paralinguistic cues)를 인식하지 못하고 단어 그 자체에만 반응합니다. 예를 들어, 떨리는 목소리로 말하는 “괜찮아요”는 문자로는 표현되지 않는 감정을 담고 있으며, 격앙된 고객의 말투에 맞춰 상담사가 말하는 속도를 낮추는 것도 텍스트만으로는 구현하기 어렵습니다.\u003C/p>\n\u003Cp>이처럼 실제 상황에서 사람과 사람 사이의 상호작용은 텍스트로 환원되기 어려운 정보들로 가득 차 있습니다.\u003C/p>\n\u003Cp>그래서, Audio LLM은 단순한 텍스트 LLM의 확장이 아니라, 인간과 기계 간 소통 방식을 근본적으로 바꾸는 새로운 패러다임이라고 할 수 있습니다. 이 섹션에서는 저희가 Audio LLM을 설계하며 겪은 기술적 고민과 구조적 선택에 대한 내용을 공유드리고자 합니다.\u003C/p>\n\u003Ch3 id=\"kanana-a의-개발-과정과-전체-구조\">Kanana-a의 개발 과정과 전체 구조\u003C/h3>\n\u003Cp>\u003Cstrong>Kanana-a는 텍스트와 음성을 함께 이해하고 생성할 수 있는 멀티모달 언어모델\u003C/strong>로, 전체 구조는 세 가지 주요 모듈로 구성됩니다.\u003C/p>\n\u003Cp>첫 번째는 \u003Cstrong>오디오 인코딩(audio encoding) 모듈\u003C/strong>로, 입력된 음성 신호를 멜 스펙트로그램(Mel Spectrogram)으로 변환한 후, 오디오 인코더를 통해 LLM이 처리 가능한 형태의 임베딩 벡터로 압축합니다.\u003C/p>\n\u003Cp>두 번째는 \u003Cstrong>LLM 기반 응답 생성\u003C/strong> 단계입니다. 이 과정에서 모델은 텍스트와 음성 임베딩을 함께 입력받아, 질의에 대한 의미를 통합적으로 이해하고 적절한 응답 시퀀스를 생성합니다.\u003C/p>\n\u003Cp>마지막으로, LLM에서 생성된 응답은 \u003Cstrong>오디오 디코딩(audio decoding) 모듈\u003C/strong>을 통해 사람이 들을 수 있는 실제 음성 파형으로 복원됩니다. 이 단계에서는 LLM의 응답을 참고하여 이산적인 음성 토큰을 만들어낸 뒤 멜 디코더와 보코더가 함께 사용되어 자연스러운 음성 출력을 완성합니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fb0155019600001.jpg\" alt=\"그림 3. 음성 이해 언어모델인 Kanana-a의 모델 구조. Voice Token LM으로부터 나오는 이산 음성 토큰을 실제 음성 파형으로 변경해주는 token-to-wav 합성 모듈은 그림에서 생략 되어있음.\">\u003C/p>\n\u003Ch3 id=\"오디오-인코딩-모듈\">오디오 인코딩 모듈\u003C/h3>\n\u003Cp>음성 데이터는 텍스트에 비해 입력 길이와 복잡도가 훨씬 높습니다. 예를 들어, “안녕하세요”와 같은 1초 분량의 인사말을 16kHz로 샘플링하면, 16,000개의 연속적인 숫자로 표현됩니다. 이처럼 단 몇 초의 음성도 수만 개의 숫자로 구성되기 때문에, 이를 그대로 대형 언어모델(LLM)에 입력하면 막대한 연산량과 지연(latency) 문제가 발생하게 됩니다.\u003C/p>\n\u003Cp>그렇다면 입력으로 주어지는 원본(raw) 음성 신호를 어떻게 하면 더 짧고 효율적인 형태로 바꿔 입력할 수 있을까요? 이 문제에 대한 저희의 고민과 경험을 바로 이어서 공유드리겠습니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fb7abb019600001.jpg\" alt=\"그림 4. 오디오 인코딩 모듈. 입력으로 들어오는 음성 신호가 mel spectrogram으로의 변환을 거쳐 Audio Encoder와 Audio Projector를 순차적으로 통과하며 LLM의 입력 벡터로 변환 됩니다.\">\u003C/p>\n\u003Ch4 id=\"오디오-인코더-raw-음성-신호를-llm-친화적인-표현으로\">오디오 인코더: Raw 음성 신호를 LLM 친화적인 표현으로\u003C/h4>\n\u003Cp>먼저, 입력된 음성 신호는 \u003Cstrong>오디오 인코더\u003C/strong>(Audio Encoder)를 통해 일정 수준 압축된 \u003Cstrong>피처 벡터\u003C/strong>(feature vector)로 변환됩니다. 일반적으로 멀티모달 언어모델에서는 각 모달리티에 대해 사전학습된 인코더(pretrained encoder)를 사용합니다.\u003C/p>\n\u003Cp>저희는 음성 인식 분야에서 널리 쓰이고 있는 OpenAI의 Whisper[1] 모델을 채택했습니다. Whisper는 96개 언어, 약 68만 시간 규모의 대규모 데이터를 학습한 모델로, MIT 라이선스 하에 공개되어 있어 제품을 개발하는 기업 입장에서도 접근성이 매우 좋은 모델이라고 할 수 있습니다.\u003C/p>\n\u003Cp>Whisper 인코더의 특징 중 하나는 높은 압축률인데요, 예를 들어, 초당 16,000개의 샘플로 구성된 음성 데이터를 멜 스펙트로그램으로 변환한 뒤 Whisper 인코더에 통과시키면, 초당 50개의 특징 벡터들만으로 표현할 수 있습니다.\u003C/p>\n\u003Ch4 id=\"더욱-짧게-압축할-순-없을까----추가적인-audio-projector의-설계\">더욱 짧게 압축할 순 없을까? -  추가적인 Audio Projector의 설계\u003C/h4>\n\u003Cp>Whisper 인코딩만으로도 압축률은 상당하지만, 1분 이상으로 음성이 길어지면 약 3,000개 이상의 피처 벡터가 생성되기 때문에 여전히 LLM 입력에는 다소 부담스러운 길이입니다. 따라서 이를 좀 더 줄이면서도 입력 음성에 있던 정보를 최대한 유지시켜 줄 수 있는 추가적인 무언가가 필요한데요, 비슷한 목적으로 Vision-LLM에서 사용되는 visual projector처럼 audio projector를 두어 이를 해결해볼 수 있습니다.\u003C/p>\n\u003Cp>저희는 Kanana-v 모델에서 사용되었던 2D-C-Abstractor[2] 구조를 변형하여, 1D 시퀀스 전용 구조인 1D-C-Abstractor를 적용했습니다. 이 모듈은 Conv1D 계열의 연산과 적절한 풀링(pooling) 기법을 조합하여, 긴 시퀀스를 더 짧으면서도 정보량이 잘 보존되도록 변환해줍니다. 이를 통해 1분 길이, 약 3,000개의 Whisper output 피처 벡터가 1D-C-Abstractor를 추가적으로 거치면서 600개 이하로 줄어들게 됩니다.\u003C/p>\n\u003Cp>이렇게 되면 대형 언어모델에 무리 없이 입력할 수 있을 정도로 입력 길이를 효과적으로 줄이면서도, 음성의 핵심 정보를 잘 유지할 수 있게 됩니다.\u003C/p>\n\u003Ch3 id=\"오디오-디코딩-모듈\">오디오 디코딩 모듈\u003C/h3>\n\u003Cp>음성을 생성하는 방식은 최근 몇 년 사이 큰 변화를 겪었습니다. 과거에는 복잡한 신호처리 기반 방식이 주를 이뤘다면, 이제는 텍스트 생성과 동일하게 \u003Cstrong>이산형 토큰\u003C/strong>(discrete token)을 예측하는 방식이 주류로 자리잡고 있습니다.\u003C/p>\n\u003Cp>오디오 디코딩 모듈에서는 유저의 질의에 대한 LLM의 답변이 Voice Token LM의 입력으로 들어가게 되고, Voice Token LM에서는 이를 바탕으로 이산화된 음성 토큰 시퀀스를 예측해줍니다. 이후 생성된 이산 음성 토큰이 Token-to-Wav 모듈을 거쳐 실제 사람이 들을 수 있는 음성 파형으로 변형되는 과정을 거칩니다.\u003C/p>\n\u003Cp>여기에서는 오디오 디코딩 모듈에서 사용되는 이산형 음성 토큰을 만드는 방법부터 시작하여, 이산 음성 토큰 시퀀스가 실제로 Voice Token LM에서 어떻게 학습되며, 최종적으로 어떻게 음성 파형으로 변환되는지에 대한 전반적인 과정에 대해 소개드리겠습니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fc0dab019600001.jpg\" alt=\"그림 5. 오디오 디코딩 모듈.\">\u003C/p>\n\u003Ch4 id=\"음성-생성도-결국-“next-token-prediction”\">음성 생성도 결국 “Next Token Prediction”\u003C/h4>\n\u003Cp>앞서 설명드린 것처럼, 음성 입력은 일반적으로 오디오 인코더를 통해 연속적인 벡터 형태로 변환됩니다. 반면, 음성의 출력은 연속적인 신호가 아닌 \u003Cstrong>이산형 토큰의 시퀀스\u003C/strong>(sequence)로 생성됩니다. 이는 GPT류의 언어모델에서 사용하는 \u003Cstrong>next token prediction\u003C/strong> 방식과 동일한 구조입니다.\u003C/p>\n\u003Cp>물론 음성과 텍스트는 문어체와 구어체의 차이, 억양, 감정 등 비언어적 요소 측면에서 다를 수 있지만, 둘 모두 의미 있는 정보를 순차적으로 담고 있는 시퀀스 데이터라는 점에서 동일한 모델링 접근이 가능합니다.\u003C/p>\n\u003Cp>결국 핵심은 학습 과정에서 오디오 토큰 시퀀스의 분포를 얼마나 잘 학습하느냐에 달려 있으며, 이 때문에 GPT류의 생성 방식이 음성 생성에도 효과적으로 적용될 수 있는 것이죠. 이렇게 생성된 토큰 시퀀스는 이후 사전학습된 Token-to-Waveform 모듈을 통해 다시 실제 음성 파형으로 변환됩니다.\u003C/p>\n\u003Ch4 id=\"이산화의-핵심-음성-토크나이저\">이산화의 핵심 음성 토크나이저\u003C/h4>\n\u003Cp>음성 데이터를 이산형 토큰으로 변환하는 핵심 모듈이 바로 \u003Cstrong>음성 토크나이저\u003C/strong>(tokenizer)입니다. 텍스트 토크나이저가 단어를 서브워드로 나누듯, 음성 토크나이저는 연속적인 오디오 신호를 짧은 단위의 코드(code)로 분해합니다.\u003C/p>\n\u003Cp>하지만 음성에는 텍스트와 달리 비언어적 정보—예를 들면 속도, 리듬, 억양, 감정 등이 포함되어 있습니다. 좋은 토크나이저는 이런 정보를 손실 없이 압축할 수 있어야 합니다. 단순히 발화 내용을 표현하는 것 이상으로, 말하는 사람의 감정이나 화법을 정확히 담아야 진정한 자연스러운 음성 합성이 가능해집니다. 이를 위해서는 대규모 데이터셋 기반의 섬세한 학습이 필수적입니다.\u003C/p>\n\u003Cp>다행히도 이러한 요구조건들을 어느정도 충족하는 다수의 공개 음성 토크나이저가 있었는데요, 저희는 안정성과 성능이 검증된 공개 음성 토크나이저 중 하나를 사용했습니다.\u003C/p>\n\u003Cp>선택한 음성 토크나이저가 세계적으로 널리 쓰이기는 하지만, 한계점도 분명하게 존재합니다. 아무래도 글로벌 범용성을 고려해 설계된 만큼, 한국어에 특화된 성능은 아직 부족하다고 할 수 있습니다. 우리가 목표로 하는 서비스는 한국어 사용자에게 최적화된 경험을 제공해야 하기에, 이 부분은 개선이 필요한 요소입니다.\u003C/p>\n\u003Cp>이러한 한계를 극복하기 위해, 저희 팀은 퍼블릭 데이터와 자체 수집 데이터를 포함한 대규모 한국어 음성 데이터셋을 기반으로 자체 음성 토크나이저 개발을 진행하고 있습니다. 한국어의 특수한 발화 구조, 억양, 어미 변화 등을 잘 반영하면서도, 스트리밍 환경에서도 잘 동작하는 고성능 음성 토크나이저를 목표로 하고 있으며, 조만간 구체적인 성과를 공유드리겠습니다.\u003C/p>\n\u003Ch4 id=\"반복-패턴과-토큰-낭비-—-음성-이산화의-숨겨진-함정\">반복 패턴과 토큰 낭비 — 음성 이산화의 숨겨진 함정\u003C/h4>\n\u003Cp>저희가 사용하고 있는 음성 토크나이저는 음성 데이터를 초당 25개의 이산 토큰으로 변환하며, 각 토큰은 약 6천여개의 코드북 항목 중 하나로 구성됩니다. 나쁘지 않은 압축률이지만, 실제 사용해보면 시퀀스가 여전히 길고 반복이 많은 구조임을 알 수 있었습니다. 예를 들어, 하나의 발음이 몇 백 ms 동안 지속될 경우, 동일한 토큰이 여러 번 반복되는 구조가 만들어집니다.\u003C/p>\n\u003Cp>이러한 반복 구조는 Transformer 기반 모델 입장에서는 일종의 \u003Cstrong>안티패턴\u003C/strong>(anti-pattern)으로 작용할 수 있습니다. 즉, 정보량은 거의 없으면서도 시퀀스를 불필요하게 늘리고, 학습 시 주의 집중(attention)을 분산시켜 오히려 학습 효율을 저하시킬 수 있는 구조입니다.\u003C/p>\n\u003Ch4 id=\"음성-토큰에도-bpe를-적용하다\">음성 토큰에도 BPE를 적용하다\u003C/h4>\n\u003Cp>이 문제를 해결하기 위해, 저희는 텍스트 토크나이징에서 검증된 기법인 \u003Cstrong>BPE\u003C/strong>(Byte Pair Encoding)를 음성 토큰에도 적용해 보기로 했습니다. BPE는 자주 등장하는 토큰 쌍을 반복적으로 병합해 시퀀스 길이를 압축시킬 수 있는 방식으로, 음성처럼 반복성이 높은 데이터에 특히 효과적이라고 할 수 있습니다.\u003C/p>\n\u003Cp>저희는 약 6천여 개의 음성 토큰으로 구성된 기존 음성 토크나이저의 토큰 시퀀스를 대상으로, BPE 기반 토크나이저를 새롭게 학습하여 적용했습니다. 그 결과, vocab size 10,000 기준으로 약 30%의 시퀀스 길이 감소 효과를 얻을 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"이산-음성-토큰-모델링\">이산 음성 토큰 모델링\u003C/h4>\n\u003Cp>음성 토크나이저와 BPE를 통해 음성 응답을 이산형 토큰 시퀀스로 표현할 수 있게 되면서, 다음으로는 이 토큰 시퀀스를 어떤 방식으로 모델링할 것인가에 대한 고민의 단계입니다. 초기의 Audio LLM 연구에서는 음성 토큰을 기존 텍스트 LLM의 vocabulary에 직접 포함시키는 방식이 주로 사용되었습니다.\u003Cbr>\n이 접근은 음성 토큰을 LLM의 임베딩 테이블과 출력 헤드에 추가하여, 텍스트와 음성을 하나의 시퀀스로 모델링하도록 하는 방식입니다. 그러나 이 방식에는 두 가지 실질적인 한계가 존재했습니다.\u003C/p>\n\u003Cp>첫째, 음성 토큰은 텍스트에 비해 시퀀스 길이가 긴 편이므로, LLM이 이를 함께 처리하면 추론 속도와 계산 효율이 급격히 떨어집니다.\u003C/p>\n\u003Cp>둘째, 임베딩과 출력 레이어 확장으로 인해 LLM 자체를 fine-tuning 해야 하며, 이 과정에서 기존 언어 지식이 손실(knowledge forgetting)될 가능성이 있습니다. 이는 서비스 품질 유지에 중요한 문제로 작용할 수 있죠.\u003C/p>\n\u003Cp>이러한 한계를 극복하기 위해, 최근에는 음성 응답 생성을 전담하는 별도의 경량 모델, 즉 \u003Cstrong>Voice Token LM\u003C/strong>을 사용하는 방식이 주목받고 있습니다. 이 방식에서는 LLM이 텍스트 형태의 응답을 먼저 생성하고, Voice Token LM은 LLM의 last hidden state를 입력으로 받아 해당 응답에 해당하는 음성 토큰 시퀀스를 생성합니다.\u003C/p>\n\u003Cp>이렇게 함으로써 텍스트 응답에 담긴 의미 정보뿐 아니라, 입력 음성의 감정이나 억양 등 음향적 힌트까지 함께 활용할 수 있어, 자연스럽고 상황에 맞는 음성 응답 생성이 가능합니다. 게다가 Voice Token LM은 일반적으로 1B 내외의 경량 모델로 구성되기 때문에, 텍스트 시퀀스 대비 긴 오디오 시퀀스를 효율적으로 처리할 수 있으며, 계산량 및 추론 시간 측면에서도 매우 유리합니다.\u003C/p>\n\u003Cp>저희 역시 앞서 소개한 두 가지 방식—LLM 단일 모델 통합 vs Voice Token LM 분리 방식—을 모두 실험적으로 비교해보았습니다. 그 결과, Voice Token LM을 활용한 방식이 연산 효율 면에서 더 우수했을 뿐 아니라, LLM의 기존 언어 지식도 안정적으로 유지되는 것을 확인할 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"이산-음성-토큰을-실제-음성으로\">이산 음성 토큰을 실제 음성으로\u003C/h4>\n\u003Cp>마지막으로는 이산 음성 토큰들을 실제 사람이 들을 수 있는 \u003Cstrong>음성 파형\u003C/strong>(waveform)으로 변환시켜주는 \u003Cstrong>token-to-wav 모듈\u003C/strong> 입니다. 이 모듈에서는 별도의 두 모델이 순차적인 두 단계에 걸쳐 사용됩니다.\u003C/p>\n\u003Cp>첫 번째 단계는 언어모델이 출력한 이산 음성 토큰으로부터 멜 스펙트로그램(mel-spectrogram)을 생성하는 과정입니다. 이를 위해 저희는 Meta에서 발표한 음성 합성 모델인 Voicebox[3]의 구조를 기반으로 자체 구축한 한국어 데이터를 추가하여 학습한 모델인 \u003Cstrong>Token-Voicebox\u003C/strong>를 활용했습니다. 이렇게 생성된 멜 스펙트로그램은 실제 음성 파형으로의 변환을 위한 중간 표현 역할을 하게 됩니다.\u003C/p>\n\u003Cp>두 번째 단계는 멜 스펙트로그램을 실제 오디오 신호로 복원하는 작업입니다. 이 단계에서는 카카오엔터프라이즈에서 개발한 보코더(Vocoder) 모델인 \u003Cstrong>Univnet\u003C/strong>[4]을 사용했습니다. Univnet은 멜 스펙트로그램을 입력으로 받아 고품질의 음성 파형을 빠르고 정확하게 생성할 수 있는 모델로, 실시간 음성 서비스에도 적합한 성능을 보여줍니다.\u003C/p>\n\u003Cp>이 과정에서 사용되는 두 모델은 이산 음성 토큰을 기반으로 사전에 학습된 모델이며, Kanana-a의 오디오 디코딩 모듈 뒤에 연결되어 inference시 실제 음성을 생성하는 용도로 사용됩니다.\u003C/p>\n\u003Ch3 id=\"학습-데이터셋-구성\">학습 데이터셋 구성\u003C/h3>\n\u003Cp>지금까지 Kanana-a의 모델 구조에 대해 설명드렸다면, 이제는 이를 뒷받침하는 학습 데이터셋 구성에 대해 소개드리고자 합니다. 강력한 음성 이해 모델을 만들기 위해서는 모델 설계 못지않게, 학습에 사용되는 데이터의 다양성과 품질이 핵심입니다.\u003C/p>\n\u003Cp>특히 음성 데이터는 공개된 고품질 데이터가 상대적으로 부족하고, 한국어 음성 데이터의 경우 영어보다 데이터 부족 문제가 심각한 상황이라는 점에서 더 많은 고민과 노력이 필요했습니다.\u003C/p>\n\u003Cp>이에 저희는 대부분의 데이터를 직접 수집하거나 가공하여, Kanana-a에 특화된 음성 학습 데이터셋을 구성했습니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fd0ad3019600001.jpg\" alt=\"그림 6. Kanana-a 학습에 활용된 데이터셋. 음성 인식 및 합성, 음성 질의 응답, 감정기반 음성 이해 및 생성, 사용자 요구 처리등 다양한 시나리오를 수행할 수 있도록 구성되어 있습니다.\">\u003C/p>\n\u003Ch4 id=\"asr--tts-음성-인식과-음성-합성의-기반-데이터\">ASR & TTS: 음성 인식과 음성 합성의 기반 데이터\u003C/h4>\n\u003Cp>음성 이해의 가장 기본이 되는 데이터는 ASR(Automatic Speech Recognition)과 TTS(Text-to-Speech) 데이터 입니다. ASR은 음성을 텍스트로 변환하는 태스크이며, TTS는 텍스트를 자연스러운 음성으로 변환하는 태스크입니다. 이 두 태스크는 음성 기반 AI 시스템의 근간이 되며, 이 기반 데이터의 품질과 규모가 이후 모든 다운스트림 태스크 성능에 큰 영향을 미칩니다.\u003C/p>\n\u003Cp>영어 도메인의 경우 음성 인식 및 음성 합성에서 퍼블릭하게 공개된 데이터들이 많기 때문에 공개 데이터들을 주로 활용하였습니다. 반면, 한국어의 경우 AI HUB에 공개된 음성 인식 데이터들을 최대한 활용하되, 부족한 부분을 보충하기 위해 성우를 고용하여 고품질의 음성 데이터를 자체적으로 수집하였습니다.\u003C/p>\n\u003Cp>이 중 TTS 태스크를 위한 데이터셋의 경우 음성 발화의 학습 대상이 되므로, 최대한 잡음없이 깔끔한 음성 발화 데이터만 남을 수 있도록 추가적인 필터링이 필요했습니다. 저희는 음성에 존재하는 잡음이나 왜곡, 자연스러움 등을 측정하는 DNSMOS(Deep Noise Suppression Mean Opinion Score)[5]와 SNR(Signal-to-Noise Ratio) 스코어를 필터링 기준으로 삼아 데이터 필터링 파이프라인을 구축 하였습니다.\u003C/p>\n\u003Cp>또한, 음성 합성 기능을 학습시킬때 고려해야할 중요한 포인트가 한 가지 더 있습니다. 다양한 소스에서 수집된 TTS 데이터는 그만큼 음성 스타일이 제각각 입니다. 이러한 데이터를 그대로 모델 학습에 활용하면 생성되는 음성 스타일 또한 일관되지 않고 매번 달라질 수 있으며, 이는 사용자의 몰입감을 저해하는 요인이 됩니다.\u003C/p>\n\u003Cp>따라서 저희는 보다 안정적이고 통일된 스타일의 음성을 생성할 필요성을 느꼈습니다. 이를 위해 전문 성우를 섭외하여 단일 화자의 음성 데이터를 별도로 수집하였고, 해당 데이터를 기반으로 모델을 튜닝함으로써 ‘카나나’만의 고유한 음성 스타일을 정립할 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"speechqa-음성-이해를-통한-질의응답-데이터\">SpeechQA: 음성 이해를 통한 질의응답 데이터\u003C/h4>\n\u003Cp>주어진 음성에 있는 내용을 그대로 text로 변환해주는 음성 인식 태스크에서 더 나아가 주어진 음성의 내용을 모두 파악하고, 유저의 질문에 해당하는 부분을 찾아 정확한 답변을 해주는 것 역시 음성 이해 모델의 중요한 능력 중 하나라고 할 수 있습니다.\u003C/p>\n\u003Cp>저희는 이러한 태스크를 SpeechQA 태스크라고 부르는데요, 이 태스크의 경우 음성 인식 및 합성 데이터셋 대비 학습용으로 쓸만한 퍼블릭 데이터가 그리 많지는 않았습니다. 이에 저희는 SpeechQA를 위한 자체 데이터셋을 직접 제작하였습니다.\u003C/p>\n\u003Cp>저희는 우선 전문 인터뷰, 강의, 뉴스 등 지식 기반 음성 데이터를 수집한 후, 일정한 길이로 잘라 단위 문맥(context)을 만들고, 각 문맥에 대해 LLM을 활용해 질의응답 쌍을 생성했습니다.\u003Cbr>\n이 데이터 덕분에 Kanana-a는 단순한 음성 반복이 아닌, 내용 이해 기반의 정답 도출 능력까지 학습할 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"emotion-recognition--generation-감정-기반-음성-이해-및-생성\">Emotion Recognition & Generation: 감정 기반 음성 이해 및 생성\u003C/h4>\n\u003Cp>사람과의 대화에서 감정은 전달되는 의미 못지않게 중요한 정보입니다. 화자의 발화로부터 음성에 담긴 감정을 정확하게 파악하고, 상황에 맞는 적절한 반응을 제공함으로써 사용자에게 신뢰성 높은 소통과 자연스러운 대화 경험을 제공할 수 있습니다.\u003C/p>\n\u003Cp>이 영역은 다행히도 AI HUB 등에서 공개된 국내외 퍼블릭 데이터가 비교적 풍부했기 때문에, 기존 데이터를 기반으로 모델을 학습시킬 수 있었습니다. 이를 통해 Kanana-a는 말투나 어조 속에 담긴 감정의 뉘앙스까지 이해하고 생성할 수 있도록 학습되었으며, 보다 풍부한 감정 표현을 통해 자연스러운 발화가 가능하도록 모델을 지속적으로 개선중입니다.\u003C/p>\n\u003Ch4 id=\"speech-instruction-following-다양한-사용자-요구에-대응하는-데이터\">Speech Instruction Following: 다양한 사용자 요구에 대응하는 데이터\u003C/h4>\n\u003Cp>마지막으로, 사용자의 다양한 지시(instruction)에 유연하게 반응하는 능력을 길러주기 위한 instruction following용 음성 데이터도 저희가 자체적으로 구축했습니다. 이 데이터는 실제 사용자 경험에 가장 가까운 형태로, 모델의 실용성 및 범용성을 크게 높여줍니다.\u003C/p>\n\u003Cp>Instruction following 데이터는 일상 대화, AI 어시스턴트, 음성 스타일 제어 등 다양한 사용자 지시에 유연하게 대응하는 능력을 기르기 위해 포괄적으로 구성되었습니다. 기존 텍스트 기반 instruction 데이터셋을 구어체화 하고 음성화하는 방식으로 대량의 데이터를 확보했으며, 더 나아가 자연어로 발화 음성의 스타일—억양, 빠르기, 화자 성별 등—을 자유롭게 컨트롤 할 수 있도록 하는 데이터셋 역시 직접 구축하였습니다. 이에 더해 한↔영 음성 통역 데이터는 AI HUB의 공개 데이터를 적극 활용하였습니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">Task\u003C/th>\n\u003Cth>Instruction\u003C/th>\n\u003Cth>\u003C/th>\n\u003Cth>\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">Voice Assistant\u003C/td>\n\u003Ctd>샐러드를 먹고 나서 배가 아픈데, 그 이유가 뭐지? 어떻게 나을 수 있을까?\u003C/td>\n\u003Ctd>\u003C/td>\n\u003Ctd>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Speech Style Control\u003C/td>\n\u003Ctd>“{Context}”에 대해 40대 남성의 중후한 목소리로 답변해줘.\u003C/td>\n\u003Ctd>\u003C/td>\n\u003Ctd>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Korean Dialect\u003C/td>\n\u003Ctd>“{Context}”는 어느 지역 방언이야? 표준어로 다시 읽어줘.\u003C/td>\n\u003Ctd>\u003C/td>\n\u003Ctd>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Translation\u003C/td>\n\u003Ctd>“{Context}”를 한국어/영어로 통역해서 말해줘.\u003C/td>\n\u003Ctd>\u003C/td>\n\u003Ctd>\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표1. Speech instruction following 데이터셋의 예시. Instruction의 경우 음성이나 텍스트 모두 지원>\u003C/center>\n\u003Ch3 id=\"학습-전략\">학습 전략\u003C/h3>\n\u003Cp>Kanana-a는 크게 Audio Encoder, Audio Projector, LLM, Voice Token LM의 4가지 주요 모듈로 구성되어 있습니다. 이들을 각각의 스테이지에서 세심하게 학습하는 것이 중요한데요, 전체적인 학습 전략은 아래 테이블과 같이 3-stage 학습 전략에 기반합니다.\u003C/p>\n\u003Cp>참고로 주요 학습 모듈 외에 voice token LM이 출력해주는 이산 음성 토큰을 멜 스펙트로그램 및 최종 음성 파형으로 변경해주는 모듈은 사전 학습된 상태로 고정하였습니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">Stages\u003C/th>\n\u003Cth align=\"center\">Training modules\u003C/th>\n\u003Cth>Data domains\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">Speech pre-training\u003C/td>\n\u003Ctd align=\"center\">1\u003C/td>\n\u003Ctd align=\"center\">Audio projector, Voice token LM\u003C/td>\n\u003Ctd>ASR, TTS\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Continued pre-training\u003C/td>\n\u003Ctd align=\"center\">2\u003C/td>\n\u003Ctd align=\"center\">Entire model\u003C/td>\n\u003Ctd>ASR, TTS, SpeechQA(일부), SER(일부)\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Supervised fine-tuning\u003C/td>\n\u003Ctd align=\"center\">3\u003C/td>\n\u003Ctd align=\"center\">Entire model\u003C/td>\n\u003Ctd>ASR, TTS, SpeechQA, SER, Speech instruction following\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표2. Kanana-a의 3-stage 학습 전략>\u003C/center>\n\u003Ch4 id=\"stage-1-speech-pretraining\">Stage-1: Speech Pretraining\u003C/h4>\n\u003Cp>먼저 첫 학습 stage에서는 Audio Projector와 Voice Token LM을 대규모 ASR 및 TTS 데이터셋을 활용해 사전학습 시킵니다. 이 단계의 핵심 목표는 이 두 모듈이 사전학습된 Audio Encoder와 LLM의 입출력 임베딩 공간에 자연스럽게 정렬(align)될 수 있도록 만드는 것입니다.\u003C/p>\n\u003Cp>이 과정을 통해 LLM은 음성 입력을 이해하고, 텍스트 응답을 음성으로 전환시킬 수 있는 기본적인 음성 입출력 흐름을 학습하게 됩니다. 특히, 이 단계에서 해당 능력을 제대로 학습하지 않으면 이후의 학습 과정에 큰 문제가 생기기 때문에 이 단계에서 충분히 학습을 수행시킬 필요가 있습니다.\u003C/p>\n\u003Ch4 id=\"stage-2-continued-pre-training\">Stage-2: Continued pre-training\u003C/h4>\n\u003Cp>첫 스테이지에서 Audio Projector 및 Voice Token LM 사전학습을 통해 전반적인 음성 피처의 흐름을 Audio Encoder와 LLM의 입, 출력 공간에 어느정도 맞춰 주었습니다.\u003C/p>\n\u003Cp>이번 스테이지는 전체 모델을 동시에 학습하여 이러한 음성 피처 흐름의 정합성을 강화함으로써 음성 이해 및 합성 능력을 최대한 끌어올리는 단계라고 할 수 있습니다.\u003C/p>\n\u003Cp>이 단계에서는 사전학습된 Audio Encoder와 LLM도 같이 학습되는데요, ASR 및 TTS데이터에 부족한 음성의 비 언어적 정보를 같이 모델링 시키기 위해 음성 감정 인식 데이터의 일부도 같이 활용합니다. 또한 간단한 SpeechQA 데이터도 일부 활용하여 LLM이 음성 입력을 분석하고 적절한 응답을 해주도록하는 조금 더 강화된 음성 이해 능력을 학습시키고자 하였습니다.\u003C/p>\n\u003Ch4 id=\"stage-3-supervised-fine-tuning\">Stage-3: Supervised Fine-tuning\u003C/h4>\n\u003Cp>이전 스테이지들을 통해 모델이 입력 음성을 이해하고, 발화할 수 있는 기본 능력을 갖추게 되었습니다. Stage 3에서는 이를 바탕으로 유저의 지시(instruction)에 반응하고, 감정까지 고려한 자연스러운 음성 응답을 생성할 수 있도록 모델을 고도화합니다. 이를 위해 앞서 설명드린 SpeechQA, Speech Emotion Recognition & Generation, Speech Instruction Following 데이터 모두를 활용하였습니다.\u003C/p>\n\u003Cp>이 중에서 특히 Speech Instruction Following 태스크에서는 세심한 주의가 필요합니다.\u003C/p>\n\u003Cp>앞서 모델 구조 섹션에서 살짝 언급드린 것처럼, 유저의 지시에 대한 응답은 LLM이 text로 먼저 생성하게 한 뒤, Voice Token LM이 text 응답에 상응하는 음성 토큰을 생성하도록 해야 합니다. LLM이 text 응답을 먼저 생성하는 과정을 건너뛰게 되면, lightweight Voice Token LM이 유저의 지시를 바로 음성 토큰으로 바꾸는 과정에서 복잡한 요청을 제대로 이해하지 못하게되고 결국 답의 내용 뿐만 아니라 음성의 품질까지 저하될 수 있습니다.\u003C/p>\n\u003Cp>따라서 저희는 LLM이 텍스트 형태로 응답을 먼저 생성하게 하고, 그 텍스트를 Voice Token LM이 받아 음성 토큰으로 변환하는 방식으로 변경하게 되었습니다. 그리고 이 과정에서 LLM의 응답뿐만 아니라 입력으로 주어졌던 컨텍스트까지 포함하여 LLM의 last hidden state를 Voice Token LM에 전달함으로써, 단순한 텍스트 정보뿐만 아니라 감정이나 말투 같은 비언어적 정보도 함께 음성 합성 과정에서 반영될 수 있도록 했습니다.\u003C/p>\n\u003Cp>이렇게 구조를 재설계한 결과, 음성 응답의 자연스러움과 명료도가 눈에 띄게 좋아지는것을 확인할 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"learning-without-forgetting\">Learning without forgetting\u003C/h4>\n\u003Cp>Stage 2와 3에서는 LLM과 Audio Encoder까지 포함해 전체 모델을 같이 학습시키는데요, 이 과정에서 주의해야 할 중요한 이슈가 있습니다. 바로 “망각”(Catastrophic forgetting) 현상입니다.\u003C/p>\n\u003Cp>망각 현상은 이전부터 AI 모델을 학습할때 항상 부딪혀왔던 문제로, 새로운 지식을 학습시킬 때 모델이 이전에 학습했던 사전 지식을 점차 잊게되는 현상을 말합니다. 특히, ASR이나 TTS처럼 고도의 추론이 필요하지 않은 단순 변환 태스크들을 학습하다 보면 기존에 LLM이 학습했던 고도의 추론 능력이 빠르게 소실될 수 있기 때문에 이러한 망각 현상을 잘 완화시키는 것이 중요합니다. 이는 사전 학습된 가중치를 기반으로 추가적으로 fine-tuning되는 Audio Encoder에도 동일하게 적용되는 문제이죠.\u003C/p>\n\u003Cp>저희는 이를 완화시키기 위해 Kanana-v에서 수행했던 것과 마찬가지로 Audio Encoder 및 LLM의 학습률(Learning rate)을 레이어별로 섬세하게 조정하였으며, LLM 학습시 사용하였던 말뭉치(Text corpus) 데이터도 일부 포함시켜 Stage-2 및 3 학습을 진행시켰습니다. 이를 통해 다양한 언어 벤치마크들의 성능을 유지시키면서도 고도의 음성 이해 및 합성 능력을 가진 Kanana-a를 만들 수 있었습니다.\u003C/p>\n\u003Ch3 id=\"스트리밍-음성-합성\">스트리밍 음성 합성\u003C/h3>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fe1190019600001.jpg\" alt=\"그림 7. 비 스트리밍 음성 합성 방식과 스트리밍 합성 방식. (위) 비 스트리밍 방식은 전체 음성 토큰이 생성될때까지 기다리고, (아래) 스트리밍 방식은 실시간으로 음성 토큰을 생성하여 유저에게 전달합니다.\">\u003C/p>\n\u003Cp>BPE 인코딩을 적용하여 언어모델에서 출력하는 음성 토큰의 길이를 줄이고 lightweight 한 Voice Token LM 을 사용하였음에도 불구하고, 전체 음성 토큰이 생성될때까지 기다린 다음 유저에게 답변을 제공하는 비 스트리밍 방식을 음성 대화 서비스에 적용하기엔 대기시간(latency)이 너무 큽니다.\u003C/p>\n\u003Cp>이러한 긴 대기시간을 해결하기 위해서 생성되는 답변이 전부 나올때까지 기다리는 대신, 어느정도 길이마다 생성된 답변을 바로바로 유저에게 전달하는 \u003Cstrong>스트리밍 디코딩(Streaming Decoding) 방식\u003C/strong>을 추가적으로 지원하도록 하였습니다. 이는 ChatGPT를 포함하여 다른 AI 모델들에서 주로 사용되는 방식으로, 유저가 중간중간 생성된 답변을 읽는 동시에 다음 답변 시퀀스를 생성하도록 하여 유저로 하여금 거의 지연없는 답변을 받는 느낌으로 인식될 수 있습니다.\u003C/p>\n\u003Cp>음성 대화 상황에서도 이를 적용하기 위해서는 음성 토큰을 파형으로 바꾸기 위해 기존에 학습했던 Token-Voicebox와 Univnet을 스트리밍을 지원하도록 새로 학습하거나 Chunked Inference 방식 등을 적용해서 스트리밍을 지원하는 게 일반적입니다.\u003C/p>\n\u003Cp>Kanana-a에서는 chunked inference 방식을 적용하여 스트리밍을 지원하고 있으며, 이를 통해 응답 대기시간을 크게 줄인 결과 유저는 전보다 더욱 빠르게 모델의 응답을 들을 수 있게 되었습니다.\u003C/p>\n\u003Ch2 id=\"카카오의-통합-멀티모달-언어모델-kanana-o\">카카오의 통합 멀티모달 언어모델: Kanana-o\u003C/h2>\n\u003Cp>최근 인공지능 기술은 LLM에서 Vision-centric Multimodal LLM, 그리고 이제는 Omni-modal LLM으로 진화하고 있습니다. 2024년 초까지의 멀티모달 모델 대부분은 시각 정보를 중심으로 설계되었지만, 2024년 5월 GPT-4o의 등장은 인공지능 연구자들에게 새로운 영감을 주었습니다. 감정을 담아 말하고, 사람의 말투에 따라 속도와 어조를 바꾸며, 대화 중 실시간으로 반응하는 GPT-4o의 데모는 단순한 기술적 진보를 넘어, AI가 사람과 ‘소통’할 수 있는 존재로 다가온 순간이었습니다.\u003C/p>\n\u003Cp>이제 AI는 하나의 감각만 정교하게 다루는 것으로는 충분하지 않습니다. 우리가 누군가의 표정과 말투를 동시에 읽고, 풍경을 보며 질문을 던지고, 목소리의 떨림에서 감정을 감지하는 것처럼, 인공지능 역시 단일 텍스트 입력을 넘어, 시각과 청각을 아우르는 복합적인 감각 정보에 반응할 수 있어야 진정한 상호작용이 가능해집니다.\u003C/p>\n\u003Cp>Kanana-o는 이러한 배경에서 출발한 카카오의 \u003Cstrong>통합 멀티모달 언어모델\u003C/strong>(Omni-modal LLM)입니다. 음성과 이미지, 텍스트 중 어떤 형태로든 입력을 받을 수 있고, 상황에 따라 텍스트 또는 음성으로 자연스럽게 응답할 수 있는 구조로 설계되었습니다. 이는 단순히 Kanana-a(Audio LLM)와 Kanana-v(Vision LLM)를 결합한 것에 그치지 않고, \u003Cstrong>서로 다른 감각 정보를 하나의 맥락으로 엮어내는 통합적 이해와 생성 능력\u003C/strong>을 실현하기 위한 시도입니다.\u003C/p>\n\u003Cp>이번 섹션에서는 지금까지 연구・개발한 Kanana-a와 Kanana-v를 어떻게 엮어 Kanana-o를 만들어낼 수 있었는지에 대해 학습 방식부터 데이터 수집, 정량 및 정성 결과까지 저희의 고민과 성과에 대해 자세하게 공유드려보도록 하겠습니다.\u003C/p>\n\u003Ch3 id=\"모델-구조-및-학습-전략-기본적인-학습-전략과-한계점\">모델 구조 및 학습 전략: 기본적인 학습 전략과 한계점\u003C/h3>\n\u003Cp>Kanana-a와 Kanana-v는 같은 LLM backbone을 공유합니다. 따라서 이 두 모델의 구조적인 결합은 앞서 보여드린 Kanana-a 모델에 시각 정보를 처리할 수 있는 Vision Encoder와 Visual Projector를 추가하는 것으로 Kanana-o의 모델 구조를 디자인 할 수 있습니다.\u003C/p>\n\u003Cp>이 글에서 설명드리지 않은 Kanana-v에 대해 자세한 내용이 궁금하신분은, 저희 테크 블로그의 \u003Ca href=\"https://tech.kakao.com/posts/667\">“이미지도 찰떡같이 이해하는 카카오의 멀티모달 언어모델 Kanana-v 알아보기”\u003C/a>를 참고하시는 것을 추천드립니다.\u003C/p>\n\u003Cp>\u003Cimg src=\"https://t1.kakaocdn.net/kakao_tech/image/85fe8721019600001.jpg\" alt=\"그림 8. 통합 멀티모달 언어모델인 Kanana-o의 모델 구조\">\u003C/p>\n\u003Cp>그럼 이제 시청각 정보를 아우르는 통합 멀티모달 언어모델인 Kanana-o를 학습시키는 전략에 대해 본격적으로 다뤄보도록 하겠습니다.\u003C/p>\n\u003Cp>우선 통합 멀티모달 언어모델을 학습하는 방식은 크게 두 가지로 구분될 수 있는데요, 각각의 모달리티 별 학습을 순차적으로 수행하는 순차 학습(Sequential Training)과 처음부터 모든 모달리티 데이터를 같이 학습시키는 병합 학습(Joint Training) 방식이 있습니다. EMOVA[6]에서는 이 중 병합 학습 방식이 최종적인 성능 측면에서 더 좋다는 결과를 보여주었고, 저희 역시 이를 기본 전략으로 채택하였습니다.\u003C/p>\n\u003Cp>병합 학습 방식의 경우 각각의 모달리티별 벤치마크 성능이 균형있게 잘 나온다는 장점이 있습니다. 하지만 모든 모달리티 데이터를 모든 스테이지에서 활용하다보니 스테이지별 학습 시간이 길어질 수 있고, 결국 저희는 아래와 같은 두 가지 현실적인 문제에 부딪혔습니다.\u003C/p>\n\u003Cul>\n\u003Cli>Ablation 실험의 유연성 부족 문제: 모델을 개발하면서 한 번의 학습으로 최상의 성능을 얻기는 매우 어렵습니다. 학습률, 스테이지별 전략, 데이터셋 비율 등 다양한 요소들을 탐색해야 하는데, 매번 전체 데이터를 사용해 긴 학습을 반복하는 것은 자원이 제한된 환경에서 매우 비효율적이었습니다.\u003C/li>\n\u003Cli>독립 모듈 개선 시 재학습 부담 문제: Kanana-a와 Kanana-v는 독립적으로 발전 중인 모듈입니다. 한쪽의 학습 레시피가 바뀌어 성능이 개선되더라도, 기존 방식대로라면 통합 모델인 Kanana-o를 처음부터 다시 학습해야 했습니다. 이는 연구와 서비스 모두에서 지속가능한 개발을 어렵게 만드는 요인이었습니다.\u003C/li>\n\u003C/ul>\n\u003Ch3 id=\"model-merging-병합으로-풀어낸-유연성과-학습-속도\">Model Merging: 병합으로 풀어낸 유연성과 학습 속도\u003C/h3>\n\u003Cp>이러한 문제를 해결하기 위해 저희는 최근 LLM 연구 커뮤니티에서 활발히 사용되고 있는 모델 병합(Model Merging)[7] 기법을 도입했습니다. 모델 병합은 서로 다른 태스크에 특화된 모델들을 하나의 모델로 통합시키는 방법으로, 이를 잘 활용하면 Kanana-o의 학습 시간을 엄청나게 단축시킬 수 있습니다.\u003C/p>\n\u003Cp>핵심은 Kanana-a와 Kanana-v가 같은 LLM을 공유한다는 사실인데요, 이때문에 각각 학습된 Kanana-a와 Kanana-v를 모델 병합 기법을 사용하여 자연스레 병합시킬 수 있고, 병합된 모델에 대해 마지막 stage-3 정도만 추가로 학습시키는 방식으로 학습 효율을 끌어올릴 수 있었던 것이죠. 실제로 전체를 처음부터 Joint Training으로 학습하는 것과 동등한 수준의 성능을 모델 병합 기법과 짧은 추가 학습만으로 달성할 수 있음을 확인 하였습니다.\u003C/p>\n\u003Cp>Kanana-o는 이러한 Model Merging 기법을 전략적으로 활용해, Kanana-a와 Kanana-v를 독립적으로 실험 및 개선하면서도, 필요에 따라 빠르게 통합하여 최신 성능을 반영한 통합 모델을 생성할 수 있는 구조를 확보했습니다. 결과적으로 모델 개발 관점에서 속도와 유연성, 성능을 동시에 잡는 효율적인 학습 파이프라인을 구축할 수 있었습니다.\u003C/p>\n\u003Ch4 id=\"omni-modal-학습-및-평가-데이터셋\">Omni-modal 학습 및 평가 데이터셋\u003C/h4>\n\u003Cp>기존의 Multimodal LLM 학습은 주로 이미지-텍스트, 또는 오디오-텍스트처럼 두 개의 모달리티만을 포함한 바이모달(bi-modal) 데이터셋에 의존해 왔습니다. 그러나 Kanana-o는 이미지, 오디오, 텍스트의 세 가지 입력 모달리티가 어떤 조합으로 주어지더라도 이를 유연하게 이해하고 응답할 수 있어야 하는 Omni-modal LLM입니다.\u003C/p>\n\u003Cp>따라서 저희는 기존의 두 가지 바이모달 데이터셋에서 한 걸음 더 나아가 이미지와 오디오가 함께 입력되거나 이미지, 오디오, 텍스트 세 가지 모달리티가 동시에 입력으로 들어오는 등의 더욱 다양한 시나리오들을 상정하였습니다.\u003C/p>\n\u003Cp>초기에는 기존의 두 가지 바이모달 데이터로도 어느 정도 일반화가 가능할 것이라는 기대가 있었지만, 실제 실험에서는 학습 시 보지 못한 모달리티 조합에 대해 모델의 반응이 불안정하게 나타나는 경우가 종종 있었습니다. 이러한 관찰을 토대로 저희는 제대로된 Omni-modal LLM을 학습시키려면 세 가지 모달리티가 다양하게 조합되어 들어오는 학습 데이터셋이 어느정도는 필요하다고 판단했습니다.\u003C/p>\n\u003Cp>하지만 현실적으로 이러한 삼중 조합 모달리티 데이터셋은 공개되어 있는 사례가 거의 없으며, 특히 한국어 기반으로는 사실상 전무한 상황입니다. 이러한 한계 속에서 저희는 기존 Kanana-v에서 사용했던 \u003Cstrong>이미지-텍스트 데이터셋을 기반으로 TTS 기반 음성 합성\u003C/strong>을 통해 새로운 형태의 Omni-modal 학습 데이터를 구축하였습니다.\u003C/p>\n\u003Cp>아래에서 저희가 이 새로운 데이터셋을 어떻게 만들었는지에 대해 조금 더 자세히 설명드려보도록 하겠습니다.\u003C/p>\n\u003Ch4 id=\"학습-데이터셋\">학습 데이터셋\u003C/h4>\n\u003Cp>기존 Kanana-v 모델은 철저한 정제 과정을 거친 이미지-텍스트 쌍 데이터를 기반으로 학습되었으며, 해당 데이터는 한국어와 영어 모두에서 콘텐츠 품질은 물론, 표현 다양성과 주제 분포까지 고르게 갖춘 균형 잡힌 구성을 갖추고 있습니다.\u003C/p>\n\u003Cp>저희는 이 데이터셋을 기반으로 입력 혹은 응답 텍스트에 대응되는 음성을 TTS 모델을 통해 생성함으로써, 이미지-텍스트 쌍을 이미지-오디오 혹은 이미지-오디오-텍스트 형태로 확장 하였습니다.\u003C/p>\n\u003Cp>TTS 음성 합성에는 Voicebox[3]와 StyleTTS2[8]를 기반으로 내부적으로 확보한 고성능 TTS 시스템을 사용하여 실제 발화와 유사한 품질의 음성들을 확보하였습니다. 또한, 실제 사용자 환경에 가까운 다화자 환경에서도 강건한 성능을 보장할 수 있도록 다양한 화자의 목소리를 사용하여 음성을 합성 하였습니다.\u003C/p>\n\u003Cp>이렇게 생성된 이미지-오디오-텍스트 데이터셋은 매 학습 iteration마다 다양한 입력-출력 조합을 구성하는 식으로 활용되었습니다. 예를 들어 이미지와 텍스트를 입력으로 받아 음성으로 응답하거나, 이미지와 음성을 입력으로 받아 텍스트로 설명하는 식의 조합을 자유자재로 구성할 수 있었죠.\u003C/p>\n\u003Cp>이처럼 서로 다른 모달리티 간의 연결성과 상호작용을 학습하게 함으로써, Kanana-o는 실제 환경에서도 유연하게 정보를 처리하고 적절한 형태로 응답할 수 있는 능력을 갖출 수 있었습니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/3qJooAWnk8M?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"영상1. Omni-modal 학습 데이터셋 예시\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C영상1. Omni-modal 학습 데이터셋 예시>\u003C/center>\n\u003Ch4 id=\"평가-데이터셋\">평가 데이터셋\u003C/h4>\n\u003Cp>Kanana-o는 다양한 모달리티 조합을 바탕으로 학습된 모델인 만큼, 그 성능을 정밀하게 평가하려면 Omni-modal 특성에 부합하는 맞춤형 평가셋이 필요합니다. 예를 들어, 기존 Kanana-v 모델은 이미지와 텍스트를 입력으로 받아 텍스트로 응답하는 구조였기 때문에, 텍스트 기반 응답을 평가하는 공개 벤치마크(MMB, SEED, MME 등)를 그대로 활용할 수 있었습니다.\u003C/p>\n\u003Cp>그러나 Kanana-o는 “이미지+오디오 → 텍스트” 시나리오까지 지원해야 하므로, 이를 다루는 삼중 모달 평가셋이 새롭게 요구 되었습니다.\u003C/p>\n\u003Cp>이에 저희는 학습 데이터 증강과 동일한 방식으로 기존 이미지-텍스트 벤치마크를 확장하여, \u003Cstrong>이미지-오디오 입력을 지원하는 새로운 평가셋\u003C/strong>을 구성했습니다. 구체적으로는, 기존 벤치마크의 텍스트 명령어(예: 질문)를 TTS를 통해 음성으로 변환한 뒤, 이를 이미지와 함께 입력으로 사용하고 Kanana-o의 텍스트 응답을 평가하는 방식입니다.\u003C/p>\n\u003Cp>이 방식은 입력 형식만 다를 뿐 질문의 시맨틱 정보는 동일하게 유지되기 때문에, 텍스트 입력과 오디오 입력 간 이해 성능을 직접 비교할 수 있다는 장점이 있습니다. 덕분에 Kanana-o의 다중 모달 처리 능력을 정밀하게 진단할 수 있었고, 이를 바탕으로 향후 모델 개선 방향을 설정하는 데에도 실질적인 도움이 되었습니다.\u003C/p>\n\u003Ch3 id=\"정량-성능-평가\">정량 성능 평가\u003C/h3>\n\u003Cp>지금까지 Kanana-a와 Kanana-o를 만들기 위해 데이터 수집부터 모델 구조 설계, 학습에 이르기까지 겪었던 도전과 고민의 과정을 소개해 드렸습니다. 수많은 시행착오와 치열한 고민 끝에 완성한 저희 모델은 한국어에서 압도적인 성능을 기록했고, 영어에서도 글로벌 수준의 모델들과 어깨를 나란히 할 만큼 경쟁력을 갖추었는데요. 지금부터 저희 모델의 성과를 보다 구체적인 수치와 함께 소개해 드리겠습니다.\u003C/p>\n\u003Ch4 id=\"kanana-o-음성-이해-및-생성-능력-비교\">Kanana-o 음성 이해 및 생성 능력 비교\u003C/h4>\n\u003Cp>한국어 음성 평가의 경우 세계적으로 널리 활용되는 보편적인 평가 데이터들이 아직은 많지 않습니다. 영어 데이터를 단순히 한국어로 통역해 활용할 수도 있겠지만, 이러한 방식으로는 한국어 고유의 발화 특성이나 문화적 맥락, 그리고 배경지식과 같은 중요한 요소들을 제대로 평가할 수 없습니다.\u003C/p>\n\u003Cp>이에 저희는 영어 음성 모델 평가에 주로 사용되는 태스크 카테고리를 기반으로 하여 한국어 맞춤형 평가 데이터셋을 직접 구축하였습니다. 여기에는 기본적인 음성 인식(ASR) 및 음성 합성(TTS) 뿐만 아니라, 주어진 음성 맥락에 대해 묻고 답하는 SpeechQA, 화자의 감정을 정확히 파악해야 하는 Speech Emotion Recognition(SER) 태스크들이 포함되어 있습니다.\u003C/p>\n\u003Cp>아래 표 4에서 보시는 바와 같이 Kanana-o는 한국어에 대해 모든 태스크에서 세계적으로 널리 활용되는 통합 멀티모달 언어모델들을 압도하는 성능을 보여주고 있습니다. 특히 화자의 감정을 인식하는 SER 태스크에서는 그 격차가 훨씬 큰데요, 그만큼 저희 모델은 한국어 음성에 담긴 미묘한 감정을 잘 이해하고 있다고 할 수 있습니다. 앞으로도 Kanana-o는 이를 더욱 개선하여 상황에 맞는 적절한 응답을 해줄 수 있도록 지속적으로 발전시켜 나갈 예정입니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">ASR-clean (CER↓)\u003C/th>\n\u003Cth align=\"center\">ASR-noisy (CER↓)\u003C/th>\n\u003Cth align=\"center\">TTS (CER↓)\u003C/th>\n\u003Cth align=\"center\">SpeechQA (ACC↑)\u003C/th>\n\u003Cth align=\"center\">SER (ACC↑)\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003C/td>\n\u003Ctd align=\"center\">KsponSpeech eval-clean\u003C/td>\n\u003Ctd align=\"center\">KsponSpeech eval-other\u003C/td>\n\u003Ctd align=\"center\">KsponSpeech eval-clean\u003C/td>\n\u003Ctd align=\"center\">Inhouse\u003C/td>\n\u003Ctd align=\"center\">Inhouse\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">GPT-4o\u003C/td>\n\u003Ctd align=\"center\">17.5\u003C/td>\n\u003Ctd align=\"center\">15.3\u003C/td>\n\u003Ctd align=\"center\">9.7\u003C/td>\n\u003Ctd align=\"center\">96.8\u003C/td>\n\u003Ctd align=\"center\">36.6\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Gemini-1.5-Pro\u003C/td>\n\u003Ctd align=\"center\">12.0\u003C/td>\n\u003Ctd align=\"center\">10.8\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003Ctd align=\"center\">98.4\u003C/td>\n\u003Ctd align=\"center\">33.2\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Kanana-o\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>8.5\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>8.5\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>4.1\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>98.8\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>62.7\u003C/strong>\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표 4. 한국어 음성 이해 및 생성 성능 비교. Gemini의 경우 음성 발화 기능을 지원하지 않음.>\u003C/center>\n\u003Cp>세계적으로 널리 활용되는 통합 멀티모달 언어모델들 대비 저희 Kanana-o가 글로벌 경쟁력을 갖게 하기 위해서는 영어 음성에 대한 이해 및 생성 성능이 매우 중요하다고 할 수 있습니다.\u003C/p>\n\u003Cp>이에 현재 널리 활용되고 있는 영어 음성 이해 및 생성 벤치마크에 대한 성능 비교를 수행하였습니다. 표 5에서 확인하실 수 있듯이, Kanana-o는 영어 벤치마크들에서도 세계적인 모델들 대비 충분히 경쟁력 있는 성능을 보여주고 있으며, 특히 ASR 및 TTS와 같은 근본적인 음성 이해 능력에서 우수한 성과를 기록했습니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">ASR (WER↓)\u003C/th>\n\u003Cth align=\"center\">\u003C/th>\n\u003Cth align=\"center\">TTS (WER↓)\u003C/th>\n\u003Cth align=\"center\">SpeechQA (ACC↑)\u003C/th>\n\u003Cth align=\"center\">SER (ACC↑)\u003C/th>\n\u003Cth align=\"center\">SpeechIF (GPT Score↑)\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003C/td>\n\u003Ctd align=\"center\">LibriSpeech test-clean\u003C/td>\n\u003Ctd align=\"center\">LibriSpeech test-other\u003C/td>\n\u003Ctd align=\"center\">LibriSpeech test-clean\u003C/td>\n\u003Ctd align=\"center\">Speech LlamaQA\u003C/td>\n\u003Ctd align=\"center\">MELD\u003C/td>\n\u003Ctd align=\"center\">Speech AlpacaEval\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">GPT-4o\u003C/td>\n\u003Ctd align=\"center\">2.6\u003C/td>\n\u003Ctd align=\"center\">5.5\u003C/td>\n\u003Ctd align=\"center\">3.7\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>71.7\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">33.2\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>7.4\u003C/strong>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Gemini-1.5-Pro\u003C/td>\n\u003Ctd align=\"center\">2.9\u003C/td>\n\u003Ctd align=\"center\">4.9\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003Ctd align=\"center\">48.4\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">MiniCPM-o 2.6\u003C/td>\n\u003Ctd align=\"center\">1.7\u003C/td>\n\u003Ctd align=\"center\">4.4\u003C/td>\n\u003Ctd align=\"center\">6.7\u003C/td>\n\u003Ctd align=\"center\">61.0\u003C/td>\n\u003Ctd align=\"center\">52.4\u003C/td>\n\u003Ctd align=\"center\">5.1\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Kanana-o\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>1.6\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>4.2\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>1.6\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">65.0\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>56.7\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">5.0\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표 5. 영어 음성 이해 및 생성 성능 비교. Gemini의 경우 음성 발화 기능을 지원하지 않음.>\u003C/center>\n\u003Cp>또한, Kanana-o는 한국어와 영어를 동시에 이해하고 생성할 수 있는 통합 멀티모달 모델로서 음성 통역 분야에서도 뛰어난 성능을 나타냅니다. 표 6에서 보시는 바와 같이 입력 음성에 대해 텍스트 혹은 음성으로 통역된 결과를 답해주는 음성 통역 태스크들에서도 글로벌 주요 모델들과 비교하여 손색없는 통역 성능을 확인할 수 있습니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">En-to-Kor Text (BLEU↑)\u003C/th>\n\u003Cth align=\"center\">Kor-to-En Text (BLEU↑)\u003C/th>\n\u003Cth align=\"center\">En-to-Kor Speech (BLEU↑)\u003C/th>\n\u003Cth align=\"center\">Kor-to-En Speech (BLEU↑)\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">\u003C/td>\n\u003Ctd align=\"center\">FLEURS en/kor\u003C/td>\n\u003Ctd align=\"center\">FLEURS en/kor\u003C/td>\n\u003Ctd align=\"center\">FLEURS en/kor\u003C/td>\n\u003Ctd align=\"center\">FLEURS en/kor\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">GPT-4o\u003C/td>\n\u003Ctd align=\"center\">23.4\u003C/td>\n\u003Ctd align=\"center\">24.0\u003C/td>\n\u003Ctd align=\"center\">21.8\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>23.4\u003C/strong>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Gemini-1.5-Pro\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>27.0\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">24.1\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003Ctd align=\"center\">-\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Kanana-o\u003C/td>\n\u003Ctd align=\"center\">25.4\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>24.6\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>24.2\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">22.3\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표 6. 한국어-영어 음성 통역 성능 비교. Gemini의 경우 음성 발화 기능을 지원하지 않음.>\u003C/center>\n\u003Ch4 id=\"kanana-o-이미지-오디오-통합-이해-능력-비교\">Kanana-o 이미지-오디오 통합 이해 능력 비교\u003C/h4>\n\u003Cp>단일 모달리티 입력만을 다루던 것에서 나아가, Kanana-o는 이미지, 오디오, 텍스트를 모두 아우르는 통합 멀티모달 모델을 목표로 개발되었습니다. 이처럼 다양한 형태의 입력을 동시에 이해하고 적절히 결합해 응답할 수 있는 능력은, 단순히 개별 모달리티에 대한 이해를 넘어서 모달리티 간 의미적 연결성을 얼마나 자연스럽게 학습했는가를 보여주는 핵심 지표입니다.\u003C/p>\n\u003Cp>아래에서는 Kanana-o가 이미지-오디오 입력 조합을 얼마나 효과적으로 이해하고 있는지, 그리고 기존의 대표적인 모델들과 비교해 어느정도의 경쟁력을 갖추었는지를 정량적 결과를 통해 살펴보겠습니다.\u003C/p>\n\u003Cp>먼저 살펴볼 것은 이미지에 대해 음성 및 텍스트로 주어지는 지시(instruction)를 모델이 얼마나 정확하게 이해하고 응답하는지 평가하는 벤치마크입니다. 이러한 통합 모달리티 벤치마크는 앞서 “Omni-modal 학습 및 평가 데이터셋” 섹션에서 말씀드린 것과 같이 공개된 데이터가 거의 없기 때문에 영어에서의 OmniBench를 제외하면 저희가 자체적으로 구축한 평가 데이터를 활용하였습니다.\u003C/p>\n\u003Cp>표 7과 8에서 보실 수 있듯이, Kanana-o는 음성 기반 태스크들 뿐만 아니라 통합 모달리티 벤치마크에서도 우수한 성능을 달성 하였는데요, 특히 한국어에서는 경쟁모델들 대비 가장 높은 성능을 보였습니다. 참고로, GPT-4o는 현재 이미지와 음성을 동시에 입력받는 기능을 지원하지 않아, 이번 비교에서는 제외되었습니다.\u003C/p>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">Speech MMB-Kor\u003C/th>\n\u003Cth align=\"center\">Speech MME-Kor\u003C/th>\n\u003Cth align=\"center\">Speech SEED-Kor\u003C/th>\n\u003Cth align=\"center\">Speech LlavaBench-Kor\u003C/th>\n\u003Cth align=\"center\">AVG\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">Gemini-1.5-Pro\u003C/td>\n\u003Ctd align=\"center\">68.2\u003C/td>\n\u003Ctd align=\"center\">54.0\u003C/td>\n\u003Ctd align=\"center\">68.0\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>87.9\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">69.5\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">MiniCPM-o 2.6\u003C/td>\n\u003Ctd align=\"center\">50.2\u003C/td>\n\u003Ctd align=\"center\">47.2\u003C/td>\n\u003Ctd align=\"center\">63.0\u003C/td>\n\u003Ctd align=\"center\">67.5\u003C/td>\n\u003Ctd align=\"center\">57.0\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Kanana-o\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>71.2\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>58.1\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>71.1\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">82.7\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>70.8\u003C/strong>\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표 7. 한국어 이미지-오디오 통합 이해 능력 비교>\u003C/center>\n\u003Cdiv class=\"table-wrapper\">\u003Ctable>\n\u003Cthead>\n\u003Ctr>\n\u003Cth align=\"left\">\u003C/th>\n\u003Cth align=\"center\">OmniBench\u003C/th>\n\u003Cth align=\"center\">Speech MMB-En\u003C/th>\n\u003Cth align=\"center\">Speech MME-En\u003C/th>\n\u003Cth align=\"center\">Speech SEED-En\u003C/th>\n\u003Cth align=\"center\">Speech LlavaBench-En\u003C/th>\n\u003Cth align=\"center\">AVG\u003C/th>\n\u003C/tr>\n\u003C/thead>\n\u003Ctbody>\n\u003Ctr>\n\u003Ctd align=\"left\">Gemini-1.5-Pro\u003C/td>\n\u003Ctd align=\"center\">42.9\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>77.7\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>75.3\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>75.6\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>98.1\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>73.9\u003C/strong>\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">MiniCPM-o 2.6\u003C/td>\n\u003Ctd align=\"center\">40.5\u003C/td>\n\u003Ctd align=\"center\">65.7\u003C/td>\n\u003Ctd align=\"center\">74.5\u003C/td>\n\u003Ctd align=\"center\">73.6\u003C/td>\n\u003Ctd align=\"center\">87.4\u003C/td>\n\u003Ctd align=\"center\">68.3\u003C/td>\n\u003C/tr>\n\u003Ctr>\n\u003Ctd align=\"left\">Kanana-o\u003C/td>\n\u003Ctd align=\"center\">\u003Cstrong>47.9\u003C/strong>\u003C/td>\n\u003Ctd align=\"center\">76.4\u003C/td>\n\u003Ctd align=\"center\">70.9\u003C/td>\n\u003Ctd align=\"center\">72.8\u003C/td>\n\u003Ctd align=\"center\">87.6\u003C/td>\n\u003Ctd align=\"center\">71.1\u003C/td>\n\u003C/tr>\n\u003C/tbody>\n\u003C/table>\n\u003C/div>\u003Ccenter>\u003C표 8. 영어 이미지-오디오 통합 이해 능력 비교>\u003C/center>\n\u003Ch3 id=\"kanana-o-기능과-활용-예시\">Kanana-o 기능과 활용 예시\u003C/h3>\n\u003Cp>Kanana-o는 자유로운 입출력 모달리티 조합이 가능한 모델로서 앞서 정량 평가에서 정의된 기능들 외에도 더욱 폭넓은 활용 가능성을 지니고 있습니다. 이제 Kanana-o가 제공하는 다양한 기능들을 실제 예시를 통해 살펴보고, 각 기능이 어떤 상황에서 유용하게 활용될 수 있는지 알아보겠습니다.\u003C/p>\n\u003Ch4 id=\"음성-인식-asr\">음성 인식 (ASR)\u003C/h4>\n\u003Cp>음성 인식은 음성 인터페이스에 기반을 둔 멀티모달 언어모델에서 가장 기본이 되면서도 핵심적인 능력 중 하나입니다. 저희 Kanana-o 모델은 깔끔한 음성을 인식하는 능력은 물론 배경 잡음이 섞인 음성 역시 정확하게 인식할 수 있는 능력을 갖추었습니다.\u003C/p>\n\u003Cp>다만 아래 예시에서 처럼 대부분 정확히 인식하지만 발음이 모호하게 들리는 부분에서는 이를 그대로 인식하여 스크립트를 작성하고 있습니다. 저희는 이를 더욱 개선하여 발음에 불분명한 부분이 있더라도 문맥을 고려하여 자연스러운 인식 결과를 만들어낼 수 있도록 모델을 더욱 개선하고자 합니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/Hi4V_XdRJOs?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 1. 배경 잡음이 있는 상황에서의 음성 인식 결과\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 1. 배경 잡음이 있는 상황에서의 음성 인식 결과>\u003C/center>\n\u003Ch4 id=\"음성-감정-묘사-및-감정-기반-음성-생성\">음성 감정 묘사 및 감정 기반 음성 생성\u003C/h4>\n\u003Cp>상대방의 말을 듣고 그 속에 담긴 감정을 이해한 뒤, 이에 적절하게 반응하는 능력은 원활한 소통과 자연스러운 대화를 위해 필수적입니다. Kanana-o 모델은 목소리에서 드러나는 감정을 이해할 수 있을 뿐만 아니라, 프롬프트로 주어지는 감정이나 발화 스타일에 맞춰 자연스러운 음성을 생성할 수도 있습니다.\u003C/p>\n\u003Cp>먼저 아래 예시를 통해 Kanana-o가 감정을 얼마나 세밀하게 포착할 수 있는지를 확인할 수 있습니다. 단순히 단어 위주의 감정 분류에 그치는 것이 아니라, 목소리에 스며든 억양과 분위기까지 깊이 이해하며, 듣는 이의 입장에서 어떻게 느껴질지를 섬세하게 파악하는 능력을 보여줍니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/TiUqU-cLaTY?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 2. 화자 음성에 대한 감정 묘사 결과\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 2. 화자 음성에 대한 감정 묘사 결과>\u003C/center>\n\u003Cp>Kanana-o는 감정을 섬세하게 이해하는 데 그치지 않고, 이를 바탕으로 프롬프트로 지정된 감정이나 발화 스타일에 맞춰 자연스러운 음성을 생성할 수도 있습니다. 아래 예시에서는 동일한 문장이라도 사용자의 지시에 따라 감정과 분위기에 맞는 음성을 적절히 생성해내는 Kanana-o의 능력을 확인할 수 있습니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/IkH0LFWLkGo?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 3. 프롬프트로 주어진 발화 스타일에 따른 음성 합성 결과\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 3. 프롬프트로 주어진 발화 스타일에 따른 음성 합성 결과>\u003C/center>\n\u003Ch4 id=\"방언-인식-및-표준어화\">방언 인식 및 표준어화\u003C/h4>\n\u003Cp>Kanana-o는 한국어와 한국 문화에 대한 깊은 이해를 갖춘 모델입니다. 발화되는 음성이 어떤 지역의 방언인지 정확히 인식할 수 있으며, 이러한 방언 이해 능력을 바탕으로 방언을 자연스러운 표준어로 변환하여 발화할 수 있는 능력도 갖추었습니다.\u003C/p>\n\u003Cp>아래 정성 예시 4에서는 한국의 지역별 방언에 대한 이해를 바탕으로 입력 음성이 어느지역 방언을 사용하는지 정보를 제공해줄 수 있음을 보여주며, 정성 예시 5에서는 이를 바탕으로 방언을 표준어로 변환해 발화해주는 기능까지 수행할 수 있습니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/QBu-TdtfoU8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 4. 방언 인식 결과\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 4. 방언 인식 결과>\u003C/center>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/0j2ZLGEi9ek?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 5. 방언을 표준어로 변환 후 발화하는 예시\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 5. 방언을 표준어로 변환 후 발화하는 예시>\u003C/center>\n\u003Ch4 id=\"음성-통역\">음성 통역\u003C/h4>\n\u003Cp>언어의 차이는 원활한 의사소통을 어렵게 하는 원인이 됩니다. Kanana-o는 이러한 언어적 장벽을 해소할 수 있는 기능을 제공합니다. 예를 들어 사용자가 한국어로 말하면 이를 즉시 영어로 통역하여 음성으로 전달해주고, 상대방이 영어로 말하면 이를 다시 한국어로 통역한 음성으로 들려줍니다. 이 기능은 서로 다른 언어를 사용하는 사람들 간의 자연스럽고 편안한 소통에 도움을 줄 수 있습니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/QEsxLoMNeJ8?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 6. 한/영 양 방향 음성 통역 결과\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 6. 한/영 양 방향 음성 통역 결과>\u003C/center>\n\u003Ch4 id=\"이미지-오디오-통합-이해-및-생성\">이미지-오디오 통합 이해 및 생성\u003C/h4>\n\u003Cp>Omni-modal LLM인 Kanana-o는 음성뿐만 아니라 이미지까지 동시에 이해하고 활용하여 더욱 폭넓은 소통을 지원합니다. 예를 들어, 음성 뿐만 아니라 이미지로 캡처된 영어 문서도 즉시 한국어로 번역해주거나, 이미지에 담긴 상황을 상세하게 묘사해 들려줄 수 있습니다. 또한 이미지에 관한 궁금한 점을 텍스트나 음성 형태로 질문하면, 원하는 형태로 답변을 제공받을 수 있습니다.\u003C/p>\n\u003Cp>특히 Kanana-o는 활용예시 #14의 “다섯 문장 이내”나 활용예시 #15의 “보행자 신호등의 색”등 사용자의 지시를 정확히 따르며 답변을 제공할 뿐 아니라, 활용예시 #16과 같이 어린이용 동화를 만들어 주는 등 창의적인 대답 또한 가능합니다.\u003C/p>\n\u003Cp>\u003Ciframe width=\"200\" height=\"113\" src=\"https://www.youtube.com/embed/ikuJX86T-jc?feature=oembed\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen=\"\" title=\"정성 예시 7. 이미지와 음성 및 텍스트 입력 조합에 따른 다양한 모델 응답 예시\">\u003C/iframe>\u003C/p>\n\u003Ccenter>\u003C정성 예시 7. 이미지와 음성 및 텍스트 입력 조합에 따른 다양한 모델 응답 예시>\u003C/center>\n\u003Ch2 id=\"앞으로의-목표\">앞으로의 목표\u003C/h2>\n\u003Cp>지금까지 Kanana-o를 개발하며 치열하게 고민하고 실험해온 과정, 그리고 그 결과물들을 소개해드렸습니다. Kanana-o는 음성, 이미지, 텍스트를 아우르는 Omni-modal LLM으로서 다양한 입력 조합에 유연하게 대응할 수 있도록 설계되었으며, 여러 벤치마크를 통해 글로벌 경쟁력도 입증하였습니다. 하지만 실사용 환경에 최적화되기 위해서는 여전히 해결해야 할 기술적 과제들이 존재합니다.\u003C/p>\n\u003Ch4 id=\"음성-기반-multi-turn-대화-처리\">음성 기반 Multi-turn 대화 처리\u003C/h4>\n\u003Cp>현재 Kanana-o는 단발성 음성 명령에 대한 이해와 응답에는 안정적인 성능을 보이고 있지만, 문맥을 유지한 다중 턴 음성 대화(Multi-turn dialogue) 시나리오에서는 아직 개선의 여지가있습니다. 실제 사용자 환경에서는 발화가 연속적으로 이어지고, 질문과 응답이 맥락에 따라 유기적으로 연결되기 때문에, 대화 흐름을 기억하고 문맥을 유지하는 능력이 필수적입니다. 따라서 향후에는 대화 상태를 추적하며 장기적으로 맥락을 유지할 수 있는 능력이 모델에 통합될 예정입니다.\u003C/p>\n\u003Ch4 id=\"full-duplex-음성-대화-지원\">Full-duplex 음성 대화 지원\u003C/h4>\n\u003Cp>저희 Kanana-o를 포함한 대부분의 기존 음성 기반 멀티모달 모델은 turn-taking 방식, 즉 사용자의 발화가 끝난 뒤에 시스템이 응답을 시작하는 구조로 작동합니다.\u003C/p>\n\u003Cp>하지만 사용자와 시스템이 동시에 말하고 들을 수 있는 Full-duplex 대화 구조는 보다 자연스럽고 몰입감 있는 음성 상호작용을 가능하게 합니다. 특히 보이스 어시스턴트나 AR/VR 환경처럼 실시간성이 중요한 상황에서는 이러한 동시 대화 능력이 핵심 요소가 됩니다. Kanana-o 역시 이를 중요한 발전 방향으로 보고 있으며, Full-duplex 대응 능력을 향상시키기 위한 연구를 지속적으로 진행 중입니다.\u003C/p>\n\u003Ch4 id=\"human-alignment-학습-및-안전성-강화\">Human alignment 학습 및 안전성 강화\u003C/h4>\n\u003Cp>음성 인터페이스는 텍스트보다 사용자 감정, 말투, 뉘앙스 등 비언어적 정보를 더 많이 포함하고 있기 때문에, 사용자와의 정서적 교감 및 안전성(safety) 문제가 더욱 민감하게 작용합니다. 부적절한 응답이 텍스트에서는 오해 수준으로 그칠 수 있지만, 음성에서는 더 직관적이고 민감한 방식으로 전달될 수 있기 때문이지요.\u003C/p>\n\u003Cp>따라서, RLHF(Reinforcement Learning from Human Feedback)와 같은 Human preference alignment learning 기법을 통해 Kanana-o를 더욱 개선시키기 위해 데이터 수집 및 정제부터 학습 방법론 탐색까지 다방면으로 노력을 기울이고 있습니다.\u003C/p>\n\u003Ch4 id=\"글로벌-대응을-위한-다국어-확장\">글로벌 대응을 위한 다국어 확장\u003C/h4>\n\u003Cp>Kanana-o는 현재 한국어와 영어에 특화된 데이터셋으로 학습되었지만, 글로벌 확장을 위한 다국어 지원은 중장기적으로 반드시 해결해야 할 과제입니다. 특히 음성 입력은 언어별 발화 특성, 억양, 리듬 등이 상이하기 때문에, 단순한 통역 기반이 아닌 언어별 음성 모델링 특성을 고려한 설계가 요구됩니다.\u003C/p>\n\u003Cp>이는 현재 OpenAI나 Google처럼 대규모 자원과 다국어 노하우를 보유한 기업만이 일정 수준 이상 달성할 수 있는 어려운 문제입니다만, 저희는 Kanana-o가 글로벌 수준의 경쟁력을 갖추게 하기위해 이 문제를 핵심 과제로 삼고, 꾸준히 연구를 이어갈 예정입니다.\u003C/p>\n\u003Ch2 id=\"맺음말\">맺음말\u003C/h2>\n\u003Cp>Kanana-o는 한국어와 영어 모두에서 글로벌 경쟁력을 입증한 카카오의 통합 멀티모달 언어 모델입니다. 정량적으로 측정될 수 있는 벤치마크 점수에서의 성과를 넘어, 감정 표현이나 한국어 특유의 뉘앙스까지 이해하며 사용자에게 친근하고 편안한 소통을 제공하기 위해 많은 고민과 노력을 기울였습니다.\u003C/p>\n\u003Cp>저희는 여기서 멈추지 않고, 앞서 언급드린 기술적 개선과 더불어 더욱 다양한 서비스에 Kanana-o를 접목하여 실생활 속의 편의성을 높이고자 합니다. 차세대 소통 인터페이스로서 사람들의 일상에 가치를 더할 수 있도록 끊임없이 발전해 나가겠습니다.\u003C/p>\n\u003Cp>Kanana-o의 앞으로의 여정에도 많은 관심과 응원을 부탁드리겠습니다.\u003C/p>\n\u003Ch2 id=\"함께한-사람들\">함께한 사람들\u003C/h2>\n\u003Cp>Kanana 조직의 \u003Ccode>brook.p\u003C/code>(박범희), \u003Ccode>coco.upgrade\u003C/code>(한건수), \u003Ccode>edwin.ai\u003C/code>(강우영), \u003Ccode>hulk.5\u003C/code>(오형석),  \u003Ccode>james.e\u003C/code>(이재명), \u003Ccode>jessie.e\u003C/code>(이지혜), \u003Ccode>kevin.nlp\u003C/code>(고현웅), \u003Ccode>logan.c\u003C/code>(차준범), \u003Ccode>martin.gale\u003C/code>(조대진), \u003Ccode>peter.brain\u003C/code>(노병석), \u003Ccode>samuel.brain\u003C/code>(강성훈), \u003Ccode>sonny.7\u003C/code>(손동희), \u003Ccode>welt.bae\u003C/code>(배병욱), \u003Ccode>wooner.l\u003C/code>(이동진) 이 함께했습니다.\u003C/p>\n\u003Cp>데이터 구축에 있어서는 Kanana 조직의 \u003Ccode>alan.zero\u003C/code>(노영만), \u003Ccode>el.if\u003C/code>(조민범), \u003Ccode>isaac.newton\u003C/code>(신종주), \u003Ccode>jaden.o\u003C/code>(박지호), \u003Ccode>jennie.ee\u003C/code>(이지혜), \u003Ccode>jeri.s\u003C/code>(이희현) 이 많은 도움을 주셨습니다.\u003C/p>\n\u003Ch4 id=\"감사의-말\">감사의 말\u003C/h4>\n\u003Cp>전체 내용에 대한 검수를 맡아주신 Kanana 조직의 \u003Ccode>loophy.cc\u003C/code>(조정민) 에게 감사의 말을 전합니다.\u003C/p>\n\u003Ch2 id=\"참고문헌\">참고문헌\u003C/h2>\n\u003Cp>[1] Radford, Alec, et al. “Robust speech recognition via large-scale weak supervision.” International conference on machine learning. PMLR, 2023.\u003Cbr>\n[2] Cha, Junbum, et al. “Honeybee: Locality-enhanced projector for multimodal llm.” Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2024.\u003Cbr>\n[3] Le, Matthew, et al. “Voicebox: Text-guided multilingual universal speech generation at scale.” Advances in neural information processing systems 36 (2023): 14005-14034.\u003Cbr>\n[4] Jang, Won, et al. “UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation.” Proc. Interspeech 2021. 2021.\u003Cbr>\n[5] Reddy, Chandan KA, Vishak Gopal, and Ross Cutler. “DNSMOS: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors.” ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021.\u003Cbr>\n[6] Chen, Kai, et al. “Emova: Empowering language models to see, hear and speak with vivid emotions.” arXiv preprint arXiv:2409.18042 (2024).\u003Cbr>\n[7] Wortsman, Mitchell, et al. “Model soups: averaging weights of multiple fine-tuned models improves accuracy without increasing inference time.” International conference on machine learning. PMLR, 2022.\u003Cbr>\n[8] Li, Yinghao Aaron, et al. “Styletts 2: Towards human-level text-to-speech through style diffusion and adversarial training with large speech language models.” Advances in Neural Information Processing Systems 36 (2023): 19594-19621.\u003C/p>\n",{"useComment":32},"Y",{"id":34,"title":35},701,"AI야, 문서 좀 대신 써 줘 - 2. 쪽지 시험",["Reactive",37],{},["Set"],["ShallowReactive",40],{"xovt2v3E6R":12},true,"/posts/702",["Reactive",44],{"listPaging":45,"api":55,"isOpen":58,"loading":61},{"pagingQuery":46,"pageNum":51,"routePath":53},["Ref",47],["Reactive",48],{"lastSeq":49,"firstSeq":49,"lastPageNumber":49,"firstPageNumber":49,"blockDirection":50},0,"NEXT",["Ref",52],1,["EmptyRef",54],"\"\"",{"apiBase":56},["Ref",57],"https://tech.kakao.com",{"isOpen":59},["EmptyRef",60],"false",{"isLoading":62},["EmptyRef",60]]</script>
<script>window.__NUXT__={};window.__NUXT__.config={public:{env:"production",kakaoAppKey:"572eb4b1268a65239eb00197657c819a",tenthUrl:"https://t1.kakaocdn.net/kakao_tech",fnameUrl:"https://img1.kakaocdn.net/thumb",gtag:{enabled:true,id:"G-MS10Z6SM95",initCommands:[],config:{},tags:[],loadingStrategy:"defer",url:"https://www.googletagmanager.com/gtag/js"}},app:{baseURL:"/",buildId:"17673baa-9b0e-4e77-8518-6bb5455682f4",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>